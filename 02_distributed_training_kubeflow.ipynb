{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2: Distributed Training with Kubeflow Training SDK\n",
    "\n",
    "This notebook covers:\n",
    "- Creating PyTorchJob using **kubeflow-training SDK** (programmatic approach)\n",
    "- Distributed training with PyTorch DDP\n",
    "- Using Feast features from shared storage\n",
    "- Monitoring training progress\n",
    "\n",
    "**Prerequisites:**\n",
    "- Completed Notebook 01 (Feast features ready)\n",
    "- OpenShift AI cluster with Kubeflow Training Operator\n",
    "- PVCs created for data and model storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q kubeflow-training==1.9.3 kubernetes yamlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Kubeflow Training SDK\n",
    "from kubernetes import client\n",
    "from kubeflow.training import TrainingClient\n",
    "from kubeflow.training.models import V1Volume, V1VolumeMount, V1PersistentVolumeClaimVolumeSource\n",
    "\n",
    "print('Imports successful')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training Configuration\n",
    "\n",
    "Define training parameters using YAML (following distributed-workloads pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext yamlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            require(\n                [\n                    \"notebook/js/codecell\",\n                    \"codemirror/mode/yaml/yaml\"\n                ],\n                function(cc){\n                    cc.CodeCell.options_default.highlight_modes.magic_yaml = {\n                        reg: [\"^%%yaml\"]\n                    }\n                }\n            );\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%yaml training_parameters\n",
    "\n",
    "# Model architecture\n",
    "model_type: mlp\n",
    "hidden_dims: [256, 128, 64, 32]\n",
    "dropout: 0.3\n",
    "\n",
    "# Training hyperparameters (GPU/CPU compatible)\n",
    "num_epochs: 10\n",
    "batch_size: 512  # Good for GPUs (underutilized) and CPUs (manageable)\n",
    "learning_rate: 0.0014  # Scaled for batch_size=512 (sqrt(2) * 0.001)\n",
    "weight_decay: 0.0001\n",
    "early_stopping_patience: 5\n",
    "\n",
    "# Training optimizations\n",
    "use_amp: true  # Automatic Mixed Precision (NVIDIA GPU only, auto-disabled on AMD/CPU)\n",
    "grad_clip_norm: 1.0\n",
    "\n",
    "# Data configuration\n",
    "data_source: direct  # Fast direct parquet loading (no Feast/Ray/PostgreSQL)\n",
    "data_path: /shared/feature_repo/data\n",
    "chunk_size: 15000  # Balance between I/O efficiency and memory\n",
    "sample_size: null  # Use full dataset (421k rows) - comment out for quick test\n",
    "test_size: 0.2\n",
    "val_size: 0.1\n",
    "\n",
    "# Output configuration\n",
    "model_output_dir: /shared/models\n",
    "checkpoint_every: 2\n",
    "\n",
    "# Distributed training\n",
    "backend: auto  # Auto-detect hardware: nccl (NVIDIA GPU), gloo (AMD GPU/CPU)\n",
    "seed: 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration:\n",
      "\n",
      "   model_type: mlp\n",
      "   hidden_dims: [256, 128, 64, 32]\n",
      "   dropout: 0.3\n",
      "   num_epochs: 10\n",
      "   batch_size: 512\n",
      "   learning_rate: 0.0014\n",
      "   weight_decay: 0.0001\n",
      "   early_stopping_patience: 5\n",
      "   use_amp: True\n",
      "   grad_clip_norm: 1.0\n",
      "   data_source: direct\n",
      "   data_path: /shared/feature_repo/data\n",
      "   chunk_size: 15000\n",
      "   sample_size: None\n",
      "   test_size: 0.2\n",
      "   val_size: 0.1\n",
      "   model_output_dir: /shared/models\n",
      "   checkpoint_every: 2\n",
      "   backend: auto\n",
      "   seed: 42\n"
     ]
    }
   ],
   "source": [
    "# Display configuration\n",
    "print('Training Configuration:\\n')\n",
    "for key, value in training_parameters.items():\n",
    "    print(f'   {key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure Kubeflow Training Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kubeflow Training client configured\n"
     ]
    }
   ],
   "source": [
    "# Option 1: In-cluster authentication (running in OpenShift AI workbench)\n",
    "# The client will automatically use the service account token\n",
    "# training_client = TrainingClient()\n",
    "\n",
    "# Option 2: External authentication (uncomment if connecting from outside cluster)\n",
    "token = \"<your-openshift-token>\"\n",
    "api_server = \"<your-openshift-api-server-url>\"\n",
    "configuration = client.Configuration()\n",
    "configuration.host = api_server\n",
    "configuration.api_key = {\"authorization\": f\"Bearer {token}\"}\n",
    "configuration.verify_ssl = False\n",
    "api_client = client.ApiClient(configuration)\n",
    "training_client = TrainingClient(client_configuration=api_client.configuration)\n",
    "\n",
    "print('Kubeflow Training client configured')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Submit Distributed Training Job\n",
    "\n",
    "Create PyTorchJob using kubeflow-training SDK (simplified API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_NAME = 'walmart-sales-forecasting'\n",
    "NAMESPACE='kft-feast-quickstart'\n",
    "TRAINING_IMAGE = 'quay.io/modh/training:py311-cuda124-torch251'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorchJob 'walmart-sales-forecasting' submitted successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.12/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.oai-kft-ibm.ibm.rh-ods.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import self-contained training function (compatible with SDK's inspect.getsource())\n",
    "from torch_training import training_func\n",
    "\n",
    "job = training_client.create_job(\n",
    "    job_kind=\"PyTorchJob\",\n",
    "    name=JOB_NAME,\n",
    "    namespace=NAMESPACE,\n",
    "    train_func=training_func,  # Self-contained function with all dependencies\n",
    "    parameters=training_parameters,  # YAML config passed as dict\n",
    "    \n",
    "    # Distributed training configuration\n",
    "    num_workers=2,  # 2 worker pods\n",
    "    num_procs_per_worker=1,\n",
    "    \n",
    "    # Resource allocation per worker\n",
    "    resources_per_worker={\n",
    "        \"nvidia.com/gpu\": 1,\n",
    "        \"memory\": \"40Gi\",\n",
    "        \"cpu\": 2,\n",
    "    },\n",
    "    \n",
    "    base_image=TRAINING_IMAGE,\n",
    "    \n",
    "    # Environment variables\n",
    "    env_vars={\n",
    "        # Training configuration\n",
    "        \"PYTHONUNBUFFERED\": \"1\",\n",
    "        \"NCCL_DEBUG\": \"INFO\",\n",
    "        # Ray configuration (for Feast offline store)\n",
    "        \"RAY_DEDUP_LOGS\": \"0\",\n",
    "    },\n",
    "    \n",
    "    # Package dependencies (PostgreSQL + Ray + Feast)\n",
    "    packages_to_install=[\n",
    "        # Core dependencies\n",
    "        \"pandas==2.2.3\",\n",
    "        \"numpy==2.2.0\",\n",
    "        \"pyarrow==17.0.0\",\n",
    "        \"scikit-learn==1.6.1\",\n",
    "        \"joblib>=1.3.0\",\n",
    "        # Feast with PostgreSQL and Ray support (extras ensure compatibility)\n",
    "        # \"feast[postgres,ray]==0.54.0\",  # Includes psycopg2, sqlalchemy, ray deps\n",
    "        # TorchData for streaming\n",
    "        \"torchdata>=0.7.0\",\n",
    "        # \"psycopg2==2.9.11\",\n",
    "        # \"dill>=0.4.0\",\n",
    "    ],\n",
    "    \n",
    "    # Shared PVC for Feast repo and model outputs\n",
    "    volumes=[\n",
    "        V1Volume(\n",
    "            name=\"shared-storage\",\n",
    "            persistent_volume_claim=V1PersistentVolumeClaimVolumeSource(claim_name=\"shared-storage\")\n",
    "        ),\n",
    "    ],\n",
    "    volume_mounts=[\n",
    "        V1VolumeMount(name=\"shared-storage\", mount_path=\"/shared\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(f\"PyTorchJob '{JOB_NAME}' submitted successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Monitor Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Status:\n",
      "\n",
      "Name: walmart-sales-forecasting\n",
      "Namespace: kft-feast-quickstart\n",
      "Creation: 2025-10-19 15:57:04+00:00\n",
      "\n",
      "Conditions:\n",
      "  Created: True\n",
      "    Message: PyTorchJob walmart-sales-forecasting is created.\n",
      "  Running: True\n",
      "    Message: PyTorchJob walmart-sales-forecasting is running.\n"
     ]
    }
   ],
   "source": [
    "# Get job status\n",
    "job = training_client.get_job(name=JOB_NAME, namespace=NAMESPACE, job_kind='PyTorchJob')\n",
    "\n",
    "print(f'Job Status:\\n')\n",
    "print(f'Name: {job.metadata.name}')\n",
    "print(f'Namespace: {job.metadata.namespace}')\n",
    "print(f'Creation: {job.metadata.creation_timestamp}')\n",
    "\n",
    "if job.status:\n",
    "    print(f'\\nConditions:')\n",
    "    if job.status.conditions:\n",
    "        for condition in job.status.conditions:\n",
    "            print(f'  {condition.type}: {condition.status}')\n",
    "            if condition.message:\n",
    "                print(f'    Message: {condition.message}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master Pod Logs (streaming):\n",
      "\n",
      "======================================================================\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,057 INFO     ======================================================================\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,057 INFO     STARTING DISTRIBUTED TRAINING\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,058 INFO     ======================================================================\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,058 INFO     Config: epochs=10, batch=512, lr=0.0014\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,058 INFO     Data source: direct\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,058 INFO     Data path: /shared/feature_repo/data\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,058 INFO     Output dir: /shared/models\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,058 INFO     Train/Val split: 90%/10%\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,224 INFO     Detected NVIDIA GPU: NVIDIA A100-SXM4-80GB (count: 1)\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,224 INFO     Auto-selected backend: nccl for device type: cuda\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,226 INFO     [Global Rank 0] [Local Rank 0] Using CUDA device 0\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,226 INFO     [Global Rank 0/1] [Local Rank 0] [Node 0] Backend: nccl\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,227 INFO     ======================================================================\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,227 INFO     LOADING FROM PARQUET FILES [Rank 0 of 2]\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,227 INFO     ======================================================================\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,227 INFO     Loading sales features: /shared/feature_repo/data/sales_features.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,294 INFO     Loading store features: /shared/feature_repo/data/store_features.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,319 INFO     Merging sales and store features...\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,457 INFO     Merged dataset: 421,570 rows, 24 columns\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,457 INFO     Computing on-demand transformations...\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,479 INFO     Computed 7 on-demand features\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,479 INFO     Saving 29 chunks...\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,509 INFO       Chunk 1/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0000.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,535 INFO       Chunk 2/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0001.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,561 INFO       Chunk 3/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0002.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,588 INFO       Chunk 4/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0003.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,614 INFO       Chunk 5/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0004.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,641 INFO       Chunk 6/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0005.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,667 INFO       Chunk 7/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0006.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,692 INFO       Chunk 8/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0007.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,718 INFO       Chunk 9/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0008.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,743 INFO       Chunk 10/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0009.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,768 INFO       Chunk 11/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0010.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,795 INFO       Chunk 12/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0011.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,819 INFO       Chunk 13/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0012.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,845 INFO       Chunk 14/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0013.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,872 INFO       Chunk 15/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0014.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,898 INFO       Chunk 16/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0015.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,923 INFO       Chunk 17/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0016.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,949 INFO       Chunk 18/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0017.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:33,975 INFO       Chunk 19/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0018.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:34,000 INFO       Chunk 20/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0019.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:34,026 INFO       Chunk 21/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0020.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:34,051 INFO       Chunk 22/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0021.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:34,080 INFO       Chunk 23/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0022.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:34,108 INFO       Chunk 24/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0023.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:34,134 INFO       Chunk 25/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0024.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:34,160 INFO       Chunk 26/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0025.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:34,185 INFO       Chunk 27/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0026.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:34,210 INFO       Chunk 28/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0027.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:34,216 INFO       Chunk 29/29: 1,570 rows -> /shared/models/direct_chunks/chunk_0028.parquet\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:34,216 INFO     Data loading complete: 29 chunks saved\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:34,216 INFO     [Rank 0] Synchronizing at barrier...\n",
      "[Pod walmart-sales-forecasting-master-0]: [rank0]:[W1019 15:57:34.790637722 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[Pod walmart-sales-forecasting-master-0]: walmart-sales-forecasting-master-0:76:76 [0] NCCL INFO Bootstrap : Using eth0:10.129.6.165<0>\n",
      "[Pod walmart-sales-forecasting-master-0]: walmart-sales-forecasting-master-0:76:76 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)\n",
      "[Pod walmart-sales-forecasting-master-0]: walmart-sales-forecasting-master-0:76:76 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.so\n",
      "[Pod walmart-sales-forecasting-master-0]: walmart-sales-forecasting-master-0:76:76 [0] NCCL INFO NET/Plugin: Using internal network plugin.\n",
      "[Pod walmart-sales-forecasting-master-0]: walmart-sales-forecasting-master-0:76:76 [0] NCCL INFO cudaDriverVersion 13000\n",
      "[Pod walmart-sales-forecasting-master-0]: NCCL version 2.21.5+cuda12.4\n",
      "[Pod walmart-sales-forecasting-master-0]: walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO NET/IB : No device found.\n",
      "[Pod walmart-sales-forecasting-master-0]: walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO NET/Socket : Using [0]eth0:10.129.6.165<0>\n",
      "[Pod walmart-sales-forecasting-master-0]: walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO Using non-device net plugin version 0\n",
      "[Pod walmart-sales-forecasting-master-0]: walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO Using network Socket\n",
      "[Pod walmart-sales-forecasting-master-0]: walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO ncclCommInitRank comm 0x55f572977da0 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 8010 commId 0x9fdc6b67119d0ab0 - Init START\n",
      "[Pod walmart-sales-forecasting-master-0]: walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffff\n",
      "[Pod walmart-sales-forecasting-master-0]: walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO comm 0x55f572977da0 rank 0 nRanks 2 nNodes 2 localRanks 1 localRank 0 MNNVL 0\n",
      "[Pod walmart-sales-forecasting-master-0]: walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO Channel 00/02 :    0   1\n",
      "[Pod walmart-sales-forecasting-master-0]: walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO Channel 01/02 :    0   1\n",
      "[Pod walmart-sales-forecasting-master-0]: walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1\n",
      "[Pod walmart-sales-forecasting-master-0]: walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO P2P Chunksize set to 131072\n",
      "[Pod walmart-sales-forecasting-master-0]: walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO Channel 00/0 : 1[0] -> 0[0] [receive] via NET/Socket/0\n",
      "[Pod walmart-sales-forecasting-master-0]: walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO Channel 01/0 : 1[0] -> 0[0] [receive] via NET/Socket/0\n",
      "[Pod walmart-sales-forecasting-master-0]: walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[0] [send] via NET/Socket/0\n",
      "[Pod walmart-sales-forecasting-master-0]: walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[0] [send] via NET/Socket/0\n",
      "[Pod walmart-sales-forecasting-master-0]: walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO Connected all rings\n",
      "[Pod walmart-sales-forecasting-master-0]: walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO Connected all trees\n",
      "[Pod walmart-sales-forecasting-master-0]: walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512\n",
      "[Pod walmart-sales-forecasting-master-0]: walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO 2 coll channels, 2 collnet channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peer\n",
      "[Pod walmart-sales-forecasting-master-0]: walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO TUNER/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.so\n",
      "[Pod walmart-sales-forecasting-master-0]: walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.\n",
      "[Pod walmart-sales-forecasting-master-0]: walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO ncclCommInitRank comm 0x55f572977da0 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 8010 commId 0x9fdc6b67119d0ab0 - Init COMPLETE\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:38,328 INFO     [Rank 0] Barrier passed\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:38,332 INFO     ======================================================================\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:38,332 INFO     PREPARING FEATURES AND SCALER [Rank 0 of 2]\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:38,332 INFO     ======================================================================\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:39,261 INFO     Encoded 29 chunks\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:39,292 INFO     Target scaling: mean=21216.09, std=25348.73\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:39,294 INFO     Fitted scaler on 15,000 samples with 27 features\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:39,294 INFO     [Rank 0] Synchronizing at barrier...\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:39,295 INFO     [Rank 0] Barrier passed - loading artifacts...\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:39,296 INFO     [Rank 0] Loaded metadata and scaler\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:39,297 INFO     Features: 27 total (base + on-demand transformations)\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:39,297 INFO     Data: 26 train chunks, 2 val chunks (trimmed for even DDP distribution)\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:40,021 INFO     [Global Rank 0/1] [Local Rank 0] Model: 27 -> [256, 128, 64, 32] -> 1\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:40,021 INFO     [Global Rank 0/1] Device: cuda:0 (CUDA), AMP: True\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:40,021 INFO     Early stopping: patience=5\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:40,021 INFO     Periodic checkpoints: every 2 epochs\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:40,399 INFO     [Rank 0/1] Epoch 0 | Batch 0 | Loss: 0.7867\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:40,795 INFO     [Rank 0/1] Epoch 0 | Batch 50 | Loss: 0.1602\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:41,318 INFO     [Rank 0/1] Epoch 0 | Batch 100 | Loss: 0.2228\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:41,836 INFO     [Rank 0/1] Epoch 0 | Batch 150 | Loss: 0.0709\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:42,232 INFO     [Rank 0/1] Epoch 0 | Batch 200 | Loss: 0.2159\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:42,659 INFO     [Rank 0/1] Epoch 0 | Batch 250 | Loss: 0.4121\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:43,085 INFO     [Rank 0/1] Epoch 0 | Batch 300 | Loss: 0.0870\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:43,558 INFO     [Rank 0/1] Epoch 0 | Batch 350 | Loss: 0.0799\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:43,809 INFO     [Rank 0] Epoch 0 training complete, 381 batches processed\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:43,810 INFO     [Rank 0] Training loss aggregated: 0.1452\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:43,810 INFO     [Rank 0] Starting validation...\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:43,844 INFO     [Rank 0] Validation batch 0\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:43,998 INFO     [Rank 0] Validation complete, 30 batches processed\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:43,998 INFO     [Rank 0] Aggregating validation loss across ranks...\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:43,999 INFO     [Rank 0] Validation loss aggregated: 0.0487\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:43,999 INFO     [Rank 0] Epoch 0 | Train Loss: 0.1452 | Val Loss: 0.0487\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:44,006 INFO     Saved best model (val_loss=0.0487)\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:44,045 INFO     [Rank 0/1] Epoch 1 | Batch 0 | Loss: 0.2678\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:44,533 INFO     [Rank 0/1] Epoch 1 | Batch 50 | Loss: 0.1541\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:44,958 INFO     [Rank 0/1] Epoch 1 | Batch 100 | Loss: 0.0462\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:45,387 INFO     [Rank 0/1] Epoch 1 | Batch 150 | Loss: 0.0669\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:45,861 INFO     [Rank 0/1] Epoch 1 | Batch 200 | Loss: 0.0965\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:46,280 INFO     [Rank 0/1] Epoch 1 | Batch 250 | Loss: 0.2469\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:46,691 INFO     [Rank 0/1] Epoch 1 | Batch 300 | Loss: 0.0507\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:47,072 INFO     [Rank 0/1] Epoch 1 | Batch 350 | Loss: 0.0517\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:47,314 INFO     [Rank 0] Epoch 1 training complete, 381 batches processed\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:47,315 INFO     [Rank 0] Training loss aggregated: 0.0879\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:47,315 INFO     [Rank 0] Starting validation...\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:47,344 INFO     [Rank 0] Validation batch 0\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:47,458 INFO     [Rank 0] Validation complete, 30 batches processed\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:47,458 INFO     [Rank 0] Aggregating validation loss across ranks...\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:47,463 INFO     [Rank 0] Validation loss aggregated: 0.0462\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:47,463 INFO     [Rank 0] Epoch 1 | Train Loss: 0.0879 | Val Loss: 0.0462\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:47,470 INFO     Saved best model (val_loss=0.0462)\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:47,476 INFO     Periodic checkpoint saved: epoch 2\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:47,514 INFO     [Rank 0/1] Epoch 2 | Batch 0 | Loss: 0.2062\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:48,000 INFO     [Rank 0/1] Epoch 2 | Batch 50 | Loss: 0.0650\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:48,412 INFO     [Rank 0/1] Epoch 2 | Batch 100 | Loss: 0.0374\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:48,917 INFO     [Rank 0/1] Epoch 2 | Batch 150 | Loss: 0.0271\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:49,299 INFO     [Rank 0/1] Epoch 2 | Batch 200 | Loss: 0.0918\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:49,714 INFO     [Rank 0/1] Epoch 2 | Batch 250 | Loss: 0.1342\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:50,127 INFO     [Rank 0/1] Epoch 2 | Batch 300 | Loss: 0.0593\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:50,505 INFO     [Rank 0/1] Epoch 2 | Batch 350 | Loss: 0.0653\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:50,747 INFO     [Rank 0] Epoch 2 training complete, 381 batches processed\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:50,748 INFO     [Rank 0] Training loss aggregated: 0.0659\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:50,748 INFO     [Rank 0] Starting validation...\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:50,780 INFO     [Rank 0] Validation batch 0\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:50,895 INFO     [Rank 0] Validation complete, 30 batches processed\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:50,895 INFO     [Rank 0] Aggregating validation loss across ranks...\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:50,897 INFO     [Rank 0] Validation loss aggregated: 0.0351\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:50,897 INFO     [Rank 0] Epoch 2 | Train Loss: 0.0659 | Val Loss: 0.0351\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:50,904 INFO     Saved best model (val_loss=0.0351)\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:50,944 INFO     [Rank 0/1] Epoch 3 | Batch 0 | Loss: 0.1096\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:51,419 INFO     [Rank 0/1] Epoch 3 | Batch 50 | Loss: 0.0533\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:51,923 INFO     [Rank 0/1] Epoch 3 | Batch 100 | Loss: 0.0286\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:52,341 INFO     [Rank 0/1] Epoch 3 | Batch 150 | Loss: 0.0377\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:52,722 INFO     [Rank 0/1] Epoch 3 | Batch 200 | Loss: 0.0956\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:53,136 INFO     [Rank 0/1] Epoch 3 | Batch 250 | Loss: 0.1238\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:53,551 INFO     [Rank 0/1] Epoch 3 | Batch 300 | Loss: 0.0788\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:53,934 INFO     [Rank 0/1] Epoch 3 | Batch 350 | Loss: 0.0410\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:54,179 INFO     [Rank 0] Epoch 3 training complete, 381 batches processed\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:54,179 INFO     [Rank 0] Training loss aggregated: 0.0598\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:54,180 INFO     [Rank 0] Starting validation...\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:54,211 INFO     [Rank 0] Validation batch 0\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:54,325 INFO     [Rank 0] Validation complete, 30 batches processed\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:54,326 INFO     [Rank 0] Aggregating validation loss across ranks...\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:54,331 INFO     [Rank 0] Validation loss aggregated: 0.0249\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:54,331 INFO     [Rank 0] Epoch 3 | Train Loss: 0.0598 | Val Loss: 0.0249\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:54,338 INFO     Saved best model (val_loss=0.0249)\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:54,344 INFO     Periodic checkpoint saved: epoch 4\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:54,384 INFO     [Rank 0/1] Epoch 4 | Batch 0 | Loss: 0.0790\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:54,975 INFO     [Rank 0/1] Epoch 4 | Batch 50 | Loss: 0.0648\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:55,397 INFO     [Rank 0/1] Epoch 4 | Batch 100 | Loss: 0.0298\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:55,814 INFO     [Rank 0/1] Epoch 4 | Batch 150 | Loss: 0.0185\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:56,199 INFO     [Rank 0/1] Epoch 4 | Batch 200 | Loss: 0.1027\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:56,622 INFO     [Rank 0/1] Epoch 4 | Batch 250 | Loss: 0.1569\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:57,052 INFO     [Rank 0/1] Epoch 4 | Batch 300 | Loss: 0.0736\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:57,448 INFO     [Rank 0/1] Epoch 4 | Batch 350 | Loss: 0.0466\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:57,707 INFO     [Rank 0] Epoch 4 training complete, 381 batches processed\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:57,708 INFO     [Rank 0] Training loss aggregated: 0.0574\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:57,708 INFO     [Rank 0] Starting validation...\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:57,741 INFO     [Rank 0] Validation batch 0\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:57,857 INFO     [Rank 0] Validation complete, 30 batches processed\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:57,857 INFO     [Rank 0] Aggregating validation loss across ranks...\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:57,861 INFO     [Rank 0] Validation loss aggregated: 0.0214\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:57,862 INFO     [Rank 0] Epoch 4 | Train Loss: 0.0574 | Val Loss: 0.0214\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:57,869 INFO     Saved best model (val_loss=0.0214)\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:57,910 INFO     [Rank 0/1] Epoch 5 | Batch 0 | Loss: 0.0829\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:58,519 INFO     [Rank 0/1] Epoch 5 | Batch 50 | Loss: 0.0639\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:58,940 INFO     [Rank 0/1] Epoch 5 | Batch 100 | Loss: 0.0315\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:59,367 INFO     [Rank 0/1] Epoch 5 | Batch 150 | Loss: 0.0217\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:57:59,755 INFO     [Rank 0/1] Epoch 5 | Batch 200 | Loss: 0.0563\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:00,177 INFO     [Rank 0/1] Epoch 5 | Batch 250 | Loss: 0.1005\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:00,594 INFO     [Rank 0/1] Epoch 5 | Batch 300 | Loss: 0.0562\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:00,976 INFO     [Rank 0/1] Epoch 5 | Batch 350 | Loss: 0.0382\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:01,228 INFO     [Rank 0] Epoch 5 training complete, 381 batches processed\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:01,229 INFO     [Rank 0] Training loss aggregated: 0.0553\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:01,229 INFO     [Rank 0] Starting validation...\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:01,260 INFO     [Rank 0] Validation batch 0\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:01,376 INFO     [Rank 0] Validation complete, 30 batches processed\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:01,376 INFO     [Rank 0] Aggregating validation loss across ranks...\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:01,385 INFO     [Rank 0] Validation loss aggregated: 0.0175\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:01,385 INFO     [Rank 0] Epoch 5 | Train Loss: 0.0553 | Val Loss: 0.0175\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:01,394 INFO     Saved best model (val_loss=0.0175)\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:01,400 INFO     Periodic checkpoint saved: epoch 6\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:01,442 INFO     [Rank 0/1] Epoch 6 | Batch 0 | Loss: 0.0574\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:02,041 INFO     [Rank 0/1] Epoch 6 | Batch 50 | Loss: 0.0346\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:02,471 INFO     [Rank 0/1] Epoch 6 | Batch 100 | Loss: 0.0334\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:02,901 INFO     [Rank 0/1] Epoch 6 | Batch 150 | Loss: 0.0170\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:03,287 INFO     [Rank 0/1] Epoch 6 | Batch 200 | Loss: 0.1129\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:03,706 INFO     [Rank 0/1] Epoch 6 | Batch 250 | Loss: 0.1301\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:04,126 INFO     [Rank 0/1] Epoch 6 | Batch 300 | Loss: 0.0883\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:04,514 INFO     [Rank 0/1] Epoch 6 | Batch 350 | Loss: 0.0963\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:04,759 INFO     [Rank 0] Epoch 6 training complete, 381 batches processed\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:04,760 INFO     [Rank 0] Training loss aggregated: 0.0552\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:04,760 INFO     [Rank 0] Starting validation...\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:04,791 INFO     [Rank 0] Validation batch 0\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:04,910 INFO     [Rank 0] Validation complete, 30 batches processed\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:04,910 INFO     [Rank 0] Aggregating validation loss across ranks...\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:04,914 INFO     [Rank 0] Validation loss aggregated: 0.0137\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:04,914 INFO     [Rank 0] Epoch 6 | Train Loss: 0.0552 | Val Loss: 0.0137\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:04,921 INFO     Saved best model (val_loss=0.0137)\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:04,961 INFO     [Rank 0/1] Epoch 7 | Batch 0 | Loss: 0.0780\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:05,532 INFO     [Rank 0/1] Epoch 7 | Batch 50 | Loss: 0.0474\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:05,983 INFO     [Rank 0/1] Epoch 7 | Batch 100 | Loss: 0.0193\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:06,404 INFO     [Rank 0/1] Epoch 7 | Batch 150 | Loss: 0.0213\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:06,803 INFO     [Rank 0/1] Epoch 7 | Batch 200 | Loss: 0.0619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.12/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.oai-kft-ibm.ibm.rh-ods.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:07,220 INFO     [Rank 0/1] Epoch 7 | Batch 250 | Loss: 0.1102\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:07,633 INFO     [Rank 0/1] Epoch 7 | Batch 300 | Loss: 0.0568\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:08,013 INFO     [Rank 0/1] Epoch 7 | Batch 350 | Loss: 0.0500\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:08,264 INFO     [Rank 0] Epoch 7 training complete, 381 batches processed\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:08,264 INFO     [Rank 0] Training loss aggregated: 0.0522\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:08,264 INFO     [Rank 0] Starting validation...\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:08,296 INFO     [Rank 0] Validation batch 0\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:08,411 INFO     [Rank 0] Validation complete, 30 batches processed\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:08,411 INFO     [Rank 0] Aggregating validation loss across ranks...\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:08,416 INFO     [Rank 0] Validation loss aggregated: 0.0184\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:08,416 INFO     [Rank 0] Epoch 7 | Train Loss: 0.0522 | Val Loss: 0.0184\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:08,423 INFO     Periodic checkpoint saved: epoch 8\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:08,463 INFO     [Rank 0/1] Epoch 8 | Batch 0 | Loss: 0.0372\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:09,038 INFO     [Rank 0/1] Epoch 8 | Batch 50 | Loss: 0.0502\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:09,455 INFO     [Rank 0/1] Epoch 8 | Batch 100 | Loss: 0.0265\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:09,868 INFO     [Rank 0/1] Epoch 8 | Batch 150 | Loss: 0.0177\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:10,255 INFO     [Rank 0/1] Epoch 8 | Batch 200 | Loss: 0.0523\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:10,672 INFO     [Rank 0/1] Epoch 8 | Batch 250 | Loss: 0.1323\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:11,102 INFO     [Rank 0/1] Epoch 8 | Batch 300 | Loss: 0.0964\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:11,487 INFO     [Rank 0/1] Epoch 8 | Batch 350 | Loss: 0.0661\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:11,734 INFO     [Rank 0] Epoch 8 training complete, 381 batches processed\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:11,735 INFO     [Rank 0] Training loss aggregated: 0.0522\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:11,735 INFO     [Rank 0] Starting validation...\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:11,868 INFO     [Rank 0] Validation batch 0\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:11,983 INFO     [Rank 0] Validation complete, 30 batches processed\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:11,984 INFO     [Rank 0] Aggregating validation loss across ranks...\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:11,984 INFO     [Rank 0] Validation loss aggregated: 0.0152\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:11,984 INFO     [Rank 0] Epoch 8 | Train Loss: 0.0522 | Val Loss: 0.0152\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:12,025 INFO     [Rank 0/1] Epoch 9 | Batch 0 | Loss: 0.0475\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:12,795 INFO     [Rank 0/1] Epoch 9 | Batch 50 | Loss: 0.0606\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:13,216 INFO     [Rank 0/1] Epoch 9 | Batch 100 | Loss: 0.0271\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:13,645 INFO     [Rank 0/1] Epoch 9 | Batch 150 | Loss: 0.0223\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:14,044 INFO     [Rank 0/1] Epoch 9 | Batch 200 | Loss: 0.0550\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:14,481 INFO     [Rank 0/1] Epoch 9 | Batch 250 | Loss: 0.1070\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:14,923 INFO     [Rank 0/1] Epoch 9 | Batch 300 | Loss: 0.0694\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:15,328 INFO     [Rank 0/1] Epoch 9 | Batch 350 | Loss: 0.1082\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:15,583 INFO     [Rank 0] Epoch 9 training complete, 381 batches processed\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:15,583 INFO     [Rank 0] Training loss aggregated: 0.0520\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:15,583 INFO     [Rank 0] Starting validation...\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:15,655 INFO     [Rank 0] Validation batch 0\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:15,771 INFO     [Rank 0] Validation complete, 30 batches processed\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:15,771 INFO     [Rank 0] Aggregating validation loss across ranks...\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:15,772 INFO     [Rank 0] Validation loss aggregated: 0.0120\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:15,772 INFO     [Rank 0] Epoch 9 | Train Loss: 0.0520 | Val Loss: 0.0120\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:15,779 INFO     Saved best model (val_loss=0.0120)\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:15,785 INFO     Periodic checkpoint saved: epoch 10\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:15,785 INFO     ======================================================================\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:15,785 INFO     FINAL VALIDATION TEST\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:15,785 INFO     ======================================================================\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:16,012 INFO     [Rank 0] Final Validation Loss: 0.0141\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:16,012 INFO     ======================================================================\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:16,012 INFO     TRAINING COMPLETE | Best Val Loss: 0.0120\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:16,012 INFO     Model saved to: /shared/models/best_model.pt\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:16,012 INFO     Feature scaler: /shared/models/scaler.pkl\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:16,012 INFO     Target scaler: /shared/models/target_scaler.pkl\n",
      "[Pod walmart-sales-forecasting-master-0]: 2025-10-19 15:58:16,012 INFO     ======================================================================\n",
      "[Pod walmart-sales-forecasting-master-0]: walmart-sales-forecasting-master-0:76:474 [0] NCCL INFO [Service thread] Connection closed by localRank 0\n",
      "[Pod walmart-sales-forecasting-master-0]: walmart-sales-forecasting-master-0:76:732 [0] NCCL INFO comm 0x55f572977da0 rank 0 nranks 2 cudaDev 0 busId 8010 - Abort COMPLETE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'walmart-sales-forecasting-master-0': '2025-10-19 15:57:33,057 INFO     ======================================================================2025-10-19 15:57:33,057 INFO     STARTING DISTRIBUTED TRAINING2025-10-19 15:57:33,058 INFO     ======================================================================2025-10-19 15:57:33,058 INFO     Config: epochs=10, batch=512, lr=0.00142025-10-19 15:57:33,058 INFO     Data source: direct2025-10-19 15:57:33,058 INFO     Data path: /shared/feature_repo/data2025-10-19 15:57:33,058 INFO     Output dir: /shared/models2025-10-19 15:57:33,058 INFO     Train/Val split: 90%/10%2025-10-19 15:57:33,224 INFO     Detected NVIDIA GPU: NVIDIA A100-SXM4-80GB (count: 1)2025-10-19 15:57:33,224 INFO     Auto-selected backend: nccl for device type: cuda2025-10-19 15:57:33,226 INFO     [Global Rank 0] [Local Rank 0] Using CUDA device 02025-10-19 15:57:33,226 INFO     [Global Rank 0/1] [Local Rank 0] [Node 0] Backend: nccl2025-10-19 15:57:33,227 INFO     ======================================================================2025-10-19 15:57:33,227 INFO     LOADING FROM PARQUET FILES [Rank 0 of 2]2025-10-19 15:57:33,227 INFO     ======================================================================2025-10-19 15:57:33,227 INFO     Loading sales features: /shared/feature_repo/data/sales_features.parquet2025-10-19 15:57:33,294 INFO     Loading store features: /shared/feature_repo/data/store_features.parquet2025-10-19 15:57:33,319 INFO     Merging sales and store features...2025-10-19 15:57:33,457 INFO     Merged dataset: 421,570 rows, 24 columns2025-10-19 15:57:33,457 INFO     Computing on-demand transformations...2025-10-19 15:57:33,479 INFO     Computed 7 on-demand features2025-10-19 15:57:33,479 INFO     Saving 29 chunks...2025-10-19 15:57:33,509 INFO       Chunk 1/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0000.parquet2025-10-19 15:57:33,535 INFO       Chunk 2/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0001.parquet2025-10-19 15:57:33,561 INFO       Chunk 3/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0002.parquet2025-10-19 15:57:33,588 INFO       Chunk 4/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0003.parquet2025-10-19 15:57:33,614 INFO       Chunk 5/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0004.parquet2025-10-19 15:57:33,641 INFO       Chunk 6/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0005.parquet2025-10-19 15:57:33,667 INFO       Chunk 7/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0006.parquet2025-10-19 15:57:33,692 INFO       Chunk 8/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0007.parquet2025-10-19 15:57:33,718 INFO       Chunk 9/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0008.parquet2025-10-19 15:57:33,743 INFO       Chunk 10/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0009.parquet2025-10-19 15:57:33,768 INFO       Chunk 11/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0010.parquet2025-10-19 15:57:33,795 INFO       Chunk 12/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0011.parquet2025-10-19 15:57:33,819 INFO       Chunk 13/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0012.parquet2025-10-19 15:57:33,845 INFO       Chunk 14/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0013.parquet2025-10-19 15:57:33,872 INFO       Chunk 15/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0014.parquet2025-10-19 15:57:33,898 INFO       Chunk 16/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0015.parquet2025-10-19 15:57:33,923 INFO       Chunk 17/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0016.parquet2025-10-19 15:57:33,949 INFO       Chunk 18/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0017.parquet2025-10-19 15:57:33,975 INFO       Chunk 19/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0018.parquet2025-10-19 15:57:34,000 INFO       Chunk 20/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0019.parquet2025-10-19 15:57:34,026 INFO       Chunk 21/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0020.parquet2025-10-19 15:57:34,051 INFO       Chunk 22/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0021.parquet2025-10-19 15:57:34,080 INFO       Chunk 23/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0022.parquet2025-10-19 15:57:34,108 INFO       Chunk 24/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0023.parquet2025-10-19 15:57:34,134 INFO       Chunk 25/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0024.parquet2025-10-19 15:57:34,160 INFO       Chunk 26/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0025.parquet2025-10-19 15:57:34,185 INFO       Chunk 27/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0026.parquet2025-10-19 15:57:34,210 INFO       Chunk 28/29: 15,000 rows -> /shared/models/direct_chunks/chunk_0027.parquet2025-10-19 15:57:34,216 INFO       Chunk 29/29: 1,570 rows -> /shared/models/direct_chunks/chunk_0028.parquet2025-10-19 15:57:34,216 INFO     Data loading complete: 29 chunks saved2025-10-19 15:57:34,216 INFO     [Rank 0] Synchronizing at barrier...[rank0]:[W1019 15:57:34.790637722 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.walmart-sales-forecasting-master-0:76:76 [0] NCCL INFO Bootstrap : Using eth0:10.129.6.165<0>walmart-sales-forecasting-master-0:76:76 [0] NCCL INFO NET/Plugin: No plugin found (libnccl-net.so)walmart-sales-forecasting-master-0:76:76 [0] NCCL INFO NET/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-net.sowalmart-sales-forecasting-master-0:76:76 [0] NCCL INFO NET/Plugin: Using internal network plugin.walmart-sales-forecasting-master-0:76:76 [0] NCCL INFO cudaDriverVersion 13000NCCL version 2.21.5+cuda12.4walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO NET/IB : No device found.walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO NET/Socket : Using [0]eth0:10.129.6.165<0>walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO Using non-device net plugin version 0walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO Using network Socketwalmart-sales-forecasting-master-0:76:472 [0] NCCL INFO ncclCommInitRank comm 0x55f572977da0 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 8010 commId 0x9fdc6b67119d0ab0 - Init STARTwalmart-sales-forecasting-master-0:76:472 [0] NCCL INFO Setting affinity for GPU 0 to ff,ffffffffwalmart-sales-forecasting-master-0:76:472 [0] NCCL INFO comm 0x55f572977da0 rank 0 nRanks 2 nNodes 2 localRanks 1 localRank 0 MNNVL 0walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO Channel 00/02 :    0   1walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO Channel 01/02 :    0   1walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] -1/-1/-1->0->1walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO P2P Chunksize set to 131072walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO Channel 00/0 : 1[0] -> 0[0] [receive] via NET/Socket/0walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO Channel 01/0 : 1[0] -> 0[0] [receive] via NET/Socket/0walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[0] [send] via NET/Socket/0walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[0] [send] via NET/Socket/0walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO Connected all ringswalmart-sales-forecasting-master-0:76:472 [0] NCCL INFO Connected all treeswalmart-sales-forecasting-master-0:76:472 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO 2 coll channels, 2 collnet channels, 0 nvls channels, 2 p2p channels, 2 p2p channels per peerwalmart-sales-forecasting-master-0:76:472 [0] NCCL INFO TUNER/Plugin: Plugin load returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory : when loading libnccl-tuner.sowalmart-sales-forecasting-master-0:76:472 [0] NCCL INFO TUNER/Plugin: Using internal tuner plugin.walmart-sales-forecasting-master-0:76:472 [0] NCCL INFO ncclCommInitRank comm 0x55f572977da0 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 8010 commId 0x9fdc6b67119d0ab0 - Init COMPLETE2025-10-19 15:57:38,328 INFO     [Rank 0] Barrier passed2025-10-19 15:57:38,332 INFO     ======================================================================2025-10-19 15:57:38,332 INFO     PREPARING FEATURES AND SCALER [Rank 0 of 2]2025-10-19 15:57:38,332 INFO     ======================================================================2025-10-19 15:57:39,261 INFO     Encoded 29 chunks2025-10-19 15:57:39,292 INFO     Target scaling: mean=21216.09, std=25348.732025-10-19 15:57:39,294 INFO     Fitted scaler on 15,000 samples with 27 features2025-10-19 15:57:39,294 INFO     [Rank 0] Synchronizing at barrier...2025-10-19 15:57:39,295 INFO     [Rank 0] Barrier passed - loading artifacts...2025-10-19 15:57:39,296 INFO     [Rank 0] Loaded metadata and scaler2025-10-19 15:57:39,297 INFO     Features: 27 total (base + on-demand transformations)2025-10-19 15:57:39,297 INFO     Data: 26 train chunks, 2 val chunks (trimmed for even DDP distribution)2025-10-19 15:57:40,021 INFO     [Global Rank 0/1] [Local Rank 0] Model: 27 -> [256, 128, 64, 32] -> 12025-10-19 15:57:40,021 INFO     [Global Rank 0/1] Device: cuda:0 (CUDA), AMP: True2025-10-19 15:57:40,021 INFO     Early stopping: patience=52025-10-19 15:57:40,021 INFO     Periodic checkpoints: every 2 epochs2025-10-19 15:57:40,399 INFO     [Rank 0/1] Epoch 0 | Batch 0 | Loss: 0.78672025-10-19 15:57:40,795 INFO     [Rank 0/1] Epoch 0 | Batch 50 | Loss: 0.16022025-10-19 15:57:41,318 INFO     [Rank 0/1] Epoch 0 | Batch 100 | Loss: 0.22282025-10-19 15:57:41,836 INFO     [Rank 0/1] Epoch 0 | Batch 150 | Loss: 0.07092025-10-19 15:57:42,232 INFO     [Rank 0/1] Epoch 0 | Batch 200 | Loss: 0.21592025-10-19 15:57:42,659 INFO     [Rank 0/1] Epoch 0 | Batch 250 | Loss: 0.41212025-10-19 15:57:43,085 INFO     [Rank 0/1] Epoch 0 | Batch 300 | Loss: 0.08702025-10-19 15:57:43,558 INFO     [Rank 0/1] Epoch 0 | Batch 350 | Loss: 0.07992025-10-19 15:57:43,809 INFO     [Rank 0] Epoch 0 training complete, 381 batches processed2025-10-19 15:57:43,810 INFO     [Rank 0] Training loss aggregated: 0.14522025-10-19 15:57:43,810 INFO     [Rank 0] Starting validation...2025-10-19 15:57:43,844 INFO     [Rank 0] Validation batch 02025-10-19 15:57:43,998 INFO     [Rank 0] Validation complete, 30 batches processed2025-10-19 15:57:43,998 INFO     [Rank 0] Aggregating validation loss across ranks...2025-10-19 15:57:43,999 INFO     [Rank 0] Validation loss aggregated: 0.04872025-10-19 15:57:43,999 INFO     [Rank 0] Epoch 0 | Train Loss: 0.1452 | Val Loss: 0.04872025-10-19 15:57:44,006 INFO     Saved best model (val_loss=0.0487)2025-10-19 15:57:44,045 INFO     [Rank 0/1] Epoch 1 | Batch 0 | Loss: 0.26782025-10-19 15:57:44,533 INFO     [Rank 0/1] Epoch 1 | Batch 50 | Loss: 0.15412025-10-19 15:57:44,958 INFO     [Rank 0/1] Epoch 1 | Batch 100 | Loss: 0.04622025-10-19 15:57:45,387 INFO     [Rank 0/1] Epoch 1 | Batch 150 | Loss: 0.06692025-10-19 15:57:45,861 INFO     [Rank 0/1] Epoch 1 | Batch 200 | Loss: 0.09652025-10-19 15:57:46,280 INFO     [Rank 0/1] Epoch 1 | Batch 250 | Loss: 0.24692025-10-19 15:57:46,691 INFO     [Rank 0/1] Epoch 1 | Batch 300 | Loss: 0.05072025-10-19 15:57:47,072 INFO     [Rank 0/1] Epoch 1 | Batch 350 | Loss: 0.05172025-10-19 15:57:47,314 INFO     [Rank 0] Epoch 1 training complete, 381 batches processed2025-10-19 15:57:47,315 INFO     [Rank 0] Training loss aggregated: 0.08792025-10-19 15:57:47,315 INFO     [Rank 0] Starting validation...2025-10-19 15:57:47,344 INFO     [Rank 0] Validation batch 02025-10-19 15:57:47,458 INFO     [Rank 0] Validation complete, 30 batches processed2025-10-19 15:57:47,458 INFO     [Rank 0] Aggregating validation loss across ranks...2025-10-19 15:57:47,463 INFO     [Rank 0] Validation loss aggregated: 0.04622025-10-19 15:57:47,463 INFO     [Rank 0] Epoch 1 | Train Loss: 0.0879 | Val Loss: 0.04622025-10-19 15:57:47,470 INFO     Saved best model (val_loss=0.0462)2025-10-19 15:57:47,476 INFO     Periodic checkpoint saved: epoch 22025-10-19 15:57:47,514 INFO     [Rank 0/1] Epoch 2 | Batch 0 | Loss: 0.20622025-10-19 15:57:48,000 INFO     [Rank 0/1] Epoch 2 | Batch 50 | Loss: 0.06502025-10-19 15:57:48,412 INFO     [Rank 0/1] Epoch 2 | Batch 100 | Loss: 0.03742025-10-19 15:57:48,917 INFO     [Rank 0/1] Epoch 2 | Batch 150 | Loss: 0.02712025-10-19 15:57:49,299 INFO     [Rank 0/1] Epoch 2 | Batch 200 | Loss: 0.09182025-10-19 15:57:49,714 INFO     [Rank 0/1] Epoch 2 | Batch 250 | Loss: 0.13422025-10-19 15:57:50,127 INFO     [Rank 0/1] Epoch 2 | Batch 300 | Loss: 0.05932025-10-19 15:57:50,505 INFO     [Rank 0/1] Epoch 2 | Batch 350 | Loss: 0.06532025-10-19 15:57:50,747 INFO     [Rank 0] Epoch 2 training complete, 381 batches processed2025-10-19 15:57:50,748 INFO     [Rank 0] Training loss aggregated: 0.06592025-10-19 15:57:50,748 INFO     [Rank 0] Starting validation...2025-10-19 15:57:50,780 INFO     [Rank 0] Validation batch 02025-10-19 15:57:50,895 INFO     [Rank 0] Validation complete, 30 batches processed2025-10-19 15:57:50,895 INFO     [Rank 0] Aggregating validation loss across ranks...2025-10-19 15:57:50,897 INFO     [Rank 0] Validation loss aggregated: 0.03512025-10-19 15:57:50,897 INFO     [Rank 0] Epoch 2 | Train Loss: 0.0659 | Val Loss: 0.03512025-10-19 15:57:50,904 INFO     Saved best model (val_loss=0.0351)2025-10-19 15:57:50,944 INFO     [Rank 0/1] Epoch 3 | Batch 0 | Loss: 0.10962025-10-19 15:57:51,419 INFO     [Rank 0/1] Epoch 3 | Batch 50 | Loss: 0.05332025-10-19 15:57:51,923 INFO     [Rank 0/1] Epoch 3 | Batch 100 | Loss: 0.02862025-10-19 15:57:52,341 INFO     [Rank 0/1] Epoch 3 | Batch 150 | Loss: 0.03772025-10-19 15:57:52,722 INFO     [Rank 0/1] Epoch 3 | Batch 200 | Loss: 0.09562025-10-19 15:57:53,136 INFO     [Rank 0/1] Epoch 3 | Batch 250 | Loss: 0.12382025-10-19 15:57:53,551 INFO     [Rank 0/1] Epoch 3 | Batch 300 | Loss: 0.07882025-10-19 15:57:53,934 INFO     [Rank 0/1] Epoch 3 | Batch 350 | Loss: 0.04102025-10-19 15:57:54,179 INFO     [Rank 0] Epoch 3 training complete, 381 batches processed2025-10-19 15:57:54,179 INFO     [Rank 0] Training loss aggregated: 0.05982025-10-19 15:57:54,180 INFO     [Rank 0] Starting validation...2025-10-19 15:57:54,211 INFO     [Rank 0] Validation batch 02025-10-19 15:57:54,325 INFO     [Rank 0] Validation complete, 30 batches processed2025-10-19 15:57:54,326 INFO     [Rank 0] Aggregating validation loss across ranks...2025-10-19 15:57:54,331 INFO     [Rank 0] Validation loss aggregated: 0.02492025-10-19 15:57:54,331 INFO     [Rank 0] Epoch 3 | Train Loss: 0.0598 | Val Loss: 0.02492025-10-19 15:57:54,338 INFO     Saved best model (val_loss=0.0249)2025-10-19 15:57:54,344 INFO     Periodic checkpoint saved: epoch 42025-10-19 15:57:54,384 INFO     [Rank 0/1] Epoch 4 | Batch 0 | Loss: 0.07902025-10-19 15:57:54,975 INFO     [Rank 0/1] Epoch 4 | Batch 50 | Loss: 0.06482025-10-19 15:57:55,397 INFO     [Rank 0/1] Epoch 4 | Batch 100 | Loss: 0.02982025-10-19 15:57:55,814 INFO     [Rank 0/1] Epoch 4 | Batch 150 | Loss: 0.01852025-10-19 15:57:56,199 INFO     [Rank 0/1] Epoch 4 | Batch 200 | Loss: 0.10272025-10-19 15:57:56,622 INFO     [Rank 0/1] Epoch 4 | Batch 250 | Loss: 0.15692025-10-19 15:57:57,052 INFO     [Rank 0/1] Epoch 4 | Batch 300 | Loss: 0.07362025-10-19 15:57:57,448 INFO     [Rank 0/1] Epoch 4 | Batch 350 | Loss: 0.04662025-10-19 15:57:57,707 INFO     [Rank 0] Epoch 4 training complete, 381 batches processed2025-10-19 15:57:57,708 INFO     [Rank 0] Training loss aggregated: 0.05742025-10-19 15:57:57,708 INFO     [Rank 0] Starting validation...2025-10-19 15:57:57,741 INFO     [Rank 0] Validation batch 02025-10-19 15:57:57,857 INFO     [Rank 0] Validation complete, 30 batches processed2025-10-19 15:57:57,857 INFO     [Rank 0] Aggregating validation loss across ranks...2025-10-19 15:57:57,861 INFO     [Rank 0] Validation loss aggregated: 0.02142025-10-19 15:57:57,862 INFO     [Rank 0] Epoch 4 | Train Loss: 0.0574 | Val Loss: 0.02142025-10-19 15:57:57,869 INFO     Saved best model (val_loss=0.0214)2025-10-19 15:57:57,910 INFO     [Rank 0/1] Epoch 5 | Batch 0 | Loss: 0.08292025-10-19 15:57:58,519 INFO     [Rank 0/1] Epoch 5 | Batch 50 | Loss: 0.06392025-10-19 15:57:58,940 INFO     [Rank 0/1] Epoch 5 | Batch 100 | Loss: 0.03152025-10-19 15:57:59,367 INFO     [Rank 0/1] Epoch 5 | Batch 150 | Loss: 0.02172025-10-19 15:57:59,755 INFO     [Rank 0/1] Epoch 5 | Batch 200 | Loss: 0.05632025-10-19 15:58:00,177 INFO     [Rank 0/1] Epoch 5 | Batch 250 | Loss: 0.10052025-10-19 15:58:00,594 INFO     [Rank 0/1] Epoch 5 | Batch 300 | Loss: 0.05622025-10-19 15:58:00,976 INFO     [Rank 0/1] Epoch 5 | Batch 350 | Loss: 0.03822025-10-19 15:58:01,228 INFO     [Rank 0] Epoch 5 training complete, 381 batches processed2025-10-19 15:58:01,229 INFO     [Rank 0] Training loss aggregated: 0.05532025-10-19 15:58:01,229 INFO     [Rank 0] Starting validation...2025-10-19 15:58:01,260 INFO     [Rank 0] Validation batch 02025-10-19 15:58:01,376 INFO     [Rank 0] Validation complete, 30 batches processed2025-10-19 15:58:01,376 INFO     [Rank 0] Aggregating validation loss across ranks...2025-10-19 15:58:01,385 INFO     [Rank 0] Validation loss aggregated: 0.01752025-10-19 15:58:01,385 INFO     [Rank 0] Epoch 5 | Train Loss: 0.0553 | Val Loss: 0.01752025-10-19 15:58:01,394 INFO     Saved best model (val_loss=0.0175)2025-10-19 15:58:01,400 INFO     Periodic checkpoint saved: epoch 62025-10-19 15:58:01,442 INFO     [Rank 0/1] Epoch 6 | Batch 0 | Loss: 0.05742025-10-19 15:58:02,041 INFO     [Rank 0/1] Epoch 6 | Batch 50 | Loss: 0.03462025-10-19 15:58:02,471 INFO     [Rank 0/1] Epoch 6 | Batch 100 | Loss: 0.03342025-10-19 15:58:02,901 INFO     [Rank 0/1] Epoch 6 | Batch 150 | Loss: 0.01702025-10-19 15:58:03,287 INFO     [Rank 0/1] Epoch 6 | Batch 200 | Loss: 0.11292025-10-19 15:58:03,706 INFO     [Rank 0/1] Epoch 6 | Batch 250 | Loss: 0.13012025-10-19 15:58:04,126 INFO     [Rank 0/1] Epoch 6 | Batch 300 | Loss: 0.08832025-10-19 15:58:04,514 INFO     [Rank 0/1] Epoch 6 | Batch 350 | Loss: 0.09632025-10-19 15:58:04,759 INFO     [Rank 0] Epoch 6 training complete, 381 batches processed2025-10-19 15:58:04,760 INFO     [Rank 0] Training loss aggregated: 0.05522025-10-19 15:58:04,760 INFO     [Rank 0] Starting validation...2025-10-19 15:58:04,791 INFO     [Rank 0] Validation batch 02025-10-19 15:58:04,910 INFO     [Rank 0] Validation complete, 30 batches processed2025-10-19 15:58:04,910 INFO     [Rank 0] Aggregating validation loss across ranks...2025-10-19 15:58:04,914 INFO     [Rank 0] Validation loss aggregated: 0.01372025-10-19 15:58:04,914 INFO     [Rank 0] Epoch 6 | Train Loss: 0.0552 | Val Loss: 0.01372025-10-19 15:58:04,921 INFO     Saved best model (val_loss=0.0137)2025-10-19 15:58:04,961 INFO     [Rank 0/1] Epoch 7 | Batch 0 | Loss: 0.07802025-10-19 15:58:05,532 INFO     [Rank 0/1] Epoch 7 | Batch 50 | Loss: 0.04742025-10-19 15:58:05,983 INFO     [Rank 0/1] Epoch 7 | Batch 100 | Loss: 0.01932025-10-19 15:58:06,404 INFO     [Rank 0/1] Epoch 7 | Batch 150 | Loss: 0.02132025-10-19 15:58:06,803 INFO     [Rank 0/1] Epoch 7 | Batch 200 | Loss: 0.06192025-10-19 15:58:07,220 INFO     [Rank 0/1] Epoch 7 | Batch 250 | Loss: 0.11022025-10-19 15:58:07,633 INFO     [Rank 0/1] Epoch 7 | Batch 300 | Loss: 0.05682025-10-19 15:58:08,013 INFO     [Rank 0/1] Epoch 7 | Batch 350 | Loss: 0.05002025-10-19 15:58:08,264 INFO     [Rank 0] Epoch 7 training complete, 381 batches processed2025-10-19 15:58:08,264 INFO     [Rank 0] Training loss aggregated: 0.05222025-10-19 15:58:08,264 INFO     [Rank 0] Starting validation...2025-10-19 15:58:08,296 INFO     [Rank 0] Validation batch 02025-10-19 15:58:08,411 INFO     [Rank 0] Validation complete, 30 batches processed2025-10-19 15:58:08,411 INFO     [Rank 0] Aggregating validation loss across ranks...2025-10-19 15:58:08,416 INFO     [Rank 0] Validation loss aggregated: 0.01842025-10-19 15:58:08,416 INFO     [Rank 0] Epoch 7 | Train Loss: 0.0522 | Val Loss: 0.01842025-10-19 15:58:08,423 INFO     Periodic checkpoint saved: epoch 82025-10-19 15:58:08,463 INFO     [Rank 0/1] Epoch 8 | Batch 0 | Loss: 0.03722025-10-19 15:58:09,038 INFO     [Rank 0/1] Epoch 8 | Batch 50 | Loss: 0.05022025-10-19 15:58:09,455 INFO     [Rank 0/1] Epoch 8 | Batch 100 | Loss: 0.02652025-10-19 15:58:09,868 INFO     [Rank 0/1] Epoch 8 | Batch 150 | Loss: 0.01772025-10-19 15:58:10,255 INFO     [Rank 0/1] Epoch 8 | Batch 200 | Loss: 0.05232025-10-19 15:58:10,672 INFO     [Rank 0/1] Epoch 8 | Batch 250 | Loss: 0.13232025-10-19 15:58:11,102 INFO     [Rank 0/1] Epoch 8 | Batch 300 | Loss: 0.09642025-10-19 15:58:11,487 INFO     [Rank 0/1] Epoch 8 | Batch 350 | Loss: 0.06612025-10-19 15:58:11,734 INFO     [Rank 0] Epoch 8 training complete, 381 batches processed2025-10-19 15:58:11,735 INFO     [Rank 0] Training loss aggregated: 0.05222025-10-19 15:58:11,735 INFO     [Rank 0] Starting validation...2025-10-19 15:58:11,868 INFO     [Rank 0] Validation batch 02025-10-19 15:58:11,983 INFO     [Rank 0] Validation complete, 30 batches processed2025-10-19 15:58:11,984 INFO     [Rank 0] Aggregating validation loss across ranks...2025-10-19 15:58:11,984 INFO     [Rank 0] Validation loss aggregated: 0.01522025-10-19 15:58:11,984 INFO     [Rank 0] Epoch 8 | Train Loss: 0.0522 | Val Loss: 0.01522025-10-19 15:58:12,025 INFO     [Rank 0/1] Epoch 9 | Batch 0 | Loss: 0.04752025-10-19 15:58:12,795 INFO     [Rank 0/1] Epoch 9 | Batch 50 | Loss: 0.06062025-10-19 15:58:13,216 INFO     [Rank 0/1] Epoch 9 | Batch 100 | Loss: 0.02712025-10-19 15:58:13,645 INFO     [Rank 0/1] Epoch 9 | Batch 150 | Loss: 0.02232025-10-19 15:58:14,044 INFO     [Rank 0/1] Epoch 9 | Batch 200 | Loss: 0.05502025-10-19 15:58:14,481 INFO     [Rank 0/1] Epoch 9 | Batch 250 | Loss: 0.10702025-10-19 15:58:14,923 INFO     [Rank 0/1] Epoch 9 | Batch 300 | Loss: 0.06942025-10-19 15:58:15,328 INFO     [Rank 0/1] Epoch 9 | Batch 350 | Loss: 0.10822025-10-19 15:58:15,583 INFO     [Rank 0] Epoch 9 training complete, 381 batches processed2025-10-19 15:58:15,583 INFO     [Rank 0] Training loss aggregated: 0.05202025-10-19 15:58:15,583 INFO     [Rank 0] Starting validation...2025-10-19 15:58:15,655 INFO     [Rank 0] Validation batch 02025-10-19 15:58:15,771 INFO     [Rank 0] Validation complete, 30 batches processed2025-10-19 15:58:15,771 INFO     [Rank 0] Aggregating validation loss across ranks...2025-10-19 15:58:15,772 INFO     [Rank 0] Validation loss aggregated: 0.01202025-10-19 15:58:15,772 INFO     [Rank 0] Epoch 9 | Train Loss: 0.0520 | Val Loss: 0.01202025-10-19 15:58:15,779 INFO     Saved best model (val_loss=0.0120)2025-10-19 15:58:15,785 INFO     Periodic checkpoint saved: epoch 102025-10-19 15:58:15,785 INFO     ======================================================================2025-10-19 15:58:15,785 INFO     FINAL VALIDATION TEST2025-10-19 15:58:15,785 INFO     ======================================================================2025-10-19 15:58:16,012 INFO     [Rank 0] Final Validation Loss: 0.01412025-10-19 15:58:16,012 INFO     ======================================================================2025-10-19 15:58:16,012 INFO     TRAINING COMPLETE | Best Val Loss: 0.01202025-10-19 15:58:16,012 INFO     Model saved to: /shared/models/best_model.pt2025-10-19 15:58:16,012 INFO     Feature scaler: /shared/models/scaler.pkl2025-10-19 15:58:16,012 INFO     Target scaler: /shared/models/target_scaler.pkl2025-10-19 15:58:16,012 INFO     ======================================================================walmart-sales-forecasting-master-0:76:474 [0] NCCL INFO [Service thread] Connection closed by localRank 0walmart-sales-forecasting-master-0:76:732 [0] NCCL INFO comm 0x55f572977da0 rank 0 nranks 2 cudaDev 0 busId 8010 - Abort COMPLETE'},\n",
       " {})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stream logs (following distributed-workloads pattern)\n",
    "print('Master Pod Logs (streaming):\\n')\n",
    "print('='*70)\n",
    "\n",
    "# Use kubeflow-training SDK to follow logs\n",
    "training_client.get_job_logs(\n",
    "    name=JOB_NAME,\n",
    "    namespace=NAMESPACE,\n",
    "    job_kind='PyTorchJob',\n",
    "    follow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Wait for Completion (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for training to complete...\n",
      "(Training takes ~40-60 min with GPUs, or 2-3 hours with CPUs)\n",
      "\n",
      "\n",
      " Training completed successfully!\n",
      "   Duration: 0 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print('Waiting for training to complete...')\n",
    "print('(Training takes ~40-60 min with GPUs, or 2-3 hours with CPUs)\\n')\n",
    "\n",
    "timeout = 7200  # 2 hours\n",
    "start_time = time.time()\n",
    "check_interval = 60\n",
    "\n",
    "while True:\n",
    "    job = training_client.get_job(name=JOB_NAME, namespace=NAMESPACE, job_kind='PyTorchJob')\n",
    "    \n",
    "    if job.status and job.status.conditions:\n",
    "        for condition in job.status.conditions:\n",
    "            if condition.type == 'Succeeded' and condition.status == 'True':\n",
    "                print(f'\\n Training completed successfully!')\n",
    "                print(f'   Duration: {int((time.time() - start_time) / 60)} minutes')\n",
    "                break\n",
    "            elif condition.type == 'Failed' and condition.status == 'True':\n",
    "                print(f'\\n Training failed: {condition.message}')\n",
    "                break\n",
    "        else:\n",
    "            elapsed = int(time.time() - start_time)\n",
    "            if elapsed > timeout:\n",
    "                print(f'\\n  Timeout reached ({timeout}s)')\n",
    "                break\n",
    "            print(f' Training in progress... ({elapsed//60} min elapsed)')\n",
    "            time.sleep(check_interval)\n",
    "            continue\n",
    "        break\n",
    "    else:\n",
    "        print(' Job starting...')\n",
    "        time.sleep(check_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.12/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.oai-kft-ibm.ibm.rh-ods.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_client.delete_job(name=JOB_NAME,namespace=NAMESPACE, job_kind='PyTorchJob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary\n",
    "\n",
    "### Completed:\n",
    " Configured kubeflow-training SDK client  \n",
    " Copied feature data to shared PVC  \n",
    " Created PyTorchJob programmatically (not YAML)  \n",
    " Submitted distributed training (1 master + 2 workers)  \n",
    " Monitored with `get_job_logs()` SDK method\n",
    "\n",
    "### Key Patterns (from distributed-workloads):\n",
    "\n",
    "**1. YAML Configuration:**\n",
    "```python\n",
    "%%yaml training_parameters\n",
    "model_type: mlp\n",
    "num_epochs: 50\n",
    "```\n",
    "\n",
    "**2. SDK Job Creation:**\n",
    "```python\n",
    "training_client.create_job(\n",
    "    job=pytorchjob,\n",
    "    namespace=NAMESPACE\n",
    ")\n",
    "```\n",
    "\n",
    "**3. Log Streaming:**\n",
    "```python\n",
    "training_client.get_job_logs(\n",
    "    name=JOB_NAME,\n",
    "    follow=True\n",
    ")\n",
    "```\n",
    "\n",
    "**4. Shared Storage:**\n",
    "- PVCs for feature_repo and models\n",
    "- Feast data accessible to all workers\n",
    "- Model checkpoints saved to shared storage\n",
    "\n",
    "### Next Steps:\n",
    "Proceed to **Notebook 03** for model evaluation and inference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
