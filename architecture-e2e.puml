@startuml Sales Demand Forecasting - E2E Architecture (PostgreSQL + Ray)
!theme plain
skinparam sequenceMessageAlign center
skinparam responseMessageBelowArrow true
skinparam boxPadding 10

title **Sales Demand Forecasting - End-to-End Architecture**\nPostgreSQL Storage + Ray Compute + Kubeflow Training

actor "Data Scientist" as DS
participant "Notebook 01\n(Data Prep)" as NB1
participant "Kaggle API" as Kaggle
database "PostgreSQL\n(feast_offline)" as PG_Offline
participant "Feast Registry\n(PostgreSQL)" as Registry
participant "Notebook 02\n(Training)" as NB2
participant "Kubeflow\nTraining Operator" as KTO
participant "PyTorchJob\n(2 Workers, DDP)" as PTJob
participant "Ray Cluster\n(8 Workers)" as Ray
database "Model Storage\n(/shared/models)" as ModelStore
participant "Notebook 03\n(Evaluation)" as NB3
database "PostgreSQL\n(feast_online)" as PG_Online

== Phase 1: Data Preparation & Feature Store Setup ==

DS -> NB1: Run data preparation
activate NB1

NB1 -> Kaggle: Download Walmart dataset\n(train.csv, features.csv, stores.csv)
Kaggle --> NB1: 421K records

NB1 -> NB1: **Feature Engineering**\n- Time-series features (lags, rolling stats)\n- Temporal features (week, month, quarter)\n- External features (temperature, CPI, markdowns)
note right: ETL Pipeline\nPre-computed features\nfor performance

NB1 -> PG_Offline: **Load to PostgreSQL**\n- sales_features (421K rows)\n- store_features (421K rows)\n- Create indexes for fast retrieval
PG_Offline --> NB1: ✓ Data loaded with indexes

NB1 -> Registry: **feast apply**\nRegister feature definitions\n- 2 FeatureViews\n- 2 OnDemandFeatureViews\n- 1 FeatureService
Registry --> NB1: ✓ Features registered

NB1 -> NB1: Test feature retrieval\n(1,000 sample rows)
NB1 --> DS: ✓ Data prep complete (5-7 min)
deactivate NB1

== Phase 2: Distributed Training ==

DS -> NB2: Configure & submit training job
activate NB2

NB2 -> NB2: **Define Training Parameters**\ndata_source: postgres_ray\nmodel_type: tft\nsample_size: 100K\nnum_epochs: 5

NB2 -> KTO: **Create PyTorchJob**\nvia kubeflow-training SDK\n- 2 workers, 1 GPU each\n- /shared PVC mounted\n- Feast + PostgreSQL + Ray deps
KTO --> NB2: ✓ Job submitted

deactivate NB2
KTO -> PTJob: Schedule training pods
activate PTJob

PTJob -> PTJob: **Rank 0 (Master)**\nInitialize DDP

PTJob -> Ray: **Initialize Ray**\nnum_cpus=8 (distributed compute)
activate Ray

PTJob -> PG_Offline: **Query entity DataFrame**\nSELECT store, dept, date\nLIMIT 100000
PG_Offline --> PTJob: Entity rows

PTJob -> Registry: **get_historical_features()**\nvia Feast SDK\nwith Ray compute engine
activate Registry

Registry -> Ray: **Distribute workload**\n- Partition data (8 workers)\n- Parallel SQL queries to PostgreSQL\n- Distributed joins (sales + store features)\n- Parallel on-demand transformations
Ray -> PG_Offline: Parallel queries\n(connection pooling)
PG_Offline --> Ray: Feature data chunks

Ray -> Ray: **Ray Processing**\n- Merge sales + store features\n- Apply OnDemandFeatureViews\n- Combine partitions
Ray --> Registry: Merged features DataFrame

deactivate Ray
Registry --> PTJob: **Training DataFrame**\n(100K rows, 31 features)\n⏱️ 1-2 min

deactivate Registry

PTJob -> PTJob: **Save chunks**\n/shared/models/postgres_ray_chunks/\n(for distributed training)

PTJob -> PTJob: **Rank 1 (Worker)**\nWait for feature loading\nSynchronize at barrier

PTJob -> PTJob: **Prepare features**\n- Categorical encoding\n- StandardScaler fit\n- Train/val split (90/10)

PTJob -> PTJob: **Training Loop (5 epochs)**\n- Temporal Fusion Transformer\n- Mixed precision (AMP)\n- DDP gradient sync\n- Early stopping (patience=5)\n⏱️ 8-10 min
note right: Distributed Training\n2 workers, DDP\nGradient aggregation\nCheckpointing

PTJob -> ModelStore: **Save artifacts**\n- best_model.pt\n- scaler.pkl\n- target_scaler.pkl
ModelStore --> PTJob: ✓ Model saved

PTJob --> KTO: Training complete\nTest MAPE: 10.5%
deactivate PTJob

KTO --> DS: ✓ Job succeeded (10-12 min)

== Phase 3: Evaluation & Materialization ==

DS -> NB3: Run evaluation & inference
activate NB3

NB3 -> ModelStore: Load trained model\n& scalers
ModelStore --> NB3: Model artifacts

NB3 -> NB3: **Evaluate on test set**\n- MAPE: 10.5%\n- MAE, RMSE metrics\n- Feature importance analysis

NB3 -> Registry: **Materialize features**\nto online store\nfor real-time inference
Registry -> PG_Offline: Read latest features
PG_Offline --> Registry: Feature data
Registry -> PG_Online: **Write feature vectors**\n(indexed by entity keys)
PG_Online --> Registry: ✓ Materialized

NB3 -> PG_Online: **Real-time inference**\n1. Read features (by entity key)\n2. Apply model\n3. Return predictions
PG_Online --> NB3: Predictions (<100ms)

NB3 --> DS: ✓ Evaluation complete\n✓ Online serving ready
deactivate NB3

== Summary ==

note over DS
**End-to-End Performance**
━━━━━━━━━━━━━━━━━━━━━━━━━━━
Phase 1: Data prep         → 5-7 min
Phase 2: Training (100K)    → 10-12 min
  - Feature loading         → 1-2 min (Ray)
  - Model training          → 8-10 min (DDP)
Phase 3: Evaluation         → 3-5 min
━━━━━━━━━━━━━━━━━━━━━━━━━━━
**Total: ~20-25 minutes**

**Architecture Benefits**
✓ 10x faster feature loading (PostgreSQL + Ray)
✓ ACID-compliant storage (PostgreSQL)
✓ Horizontal scalability (Ray distributed)
✓ Production-ready (same stack for train/serve)
✓ Feature consistency (Feast SDK)
end note

@enduml



