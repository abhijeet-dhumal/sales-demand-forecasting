# =============================================================================
# BATCH INFERENCE JOB (Ray-based)
# =============================================================================
# Demonstrates Ray's value for scoring large datasets
#
# WHY USE RAY FOR BATCH INFERENCE?
# - Score millions of entities in parallel
# - Use Feast to ensure same features as training
# - Distribute load across Ray workers
#
# WORKFLOW:
# 1. Load entities to score from parquet
# 2. Call get_online_features() via Ray (distributed)
# 3. Run model inference in parallel
# 4. Save predictions to parquet
#
apiVersion: v1
kind: ConfigMap
metadata:
  name: batch-inference-scripts
  namespace: feast-trainer-demo
data:
  batch_inference.py: |
    """
    Ray-based Batch Inference
    
    Demonstrates production-scale batch scoring:
    - Distributed feature retrieval via Feast
    - Parallel model inference via Ray
    - Results saved to parquet for downstream use
    """
    import os
    import sys
    import time
    import logging
    from datetime import datetime, timezone
    
    import numpy as np
    import pandas as pd
    import torch
    import joblib
    
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
    logger = logging.getLogger(__name__)
    
    # Paths
    DATA_PATH = os.getenv("DATA_PATH", "/shared/data")
    MODEL_PATH = os.getenv("MODEL_PATH", "/shared/models")
    OUTPUT_PATH = os.getenv("OUTPUT_PATH", "/shared/predictions")
    FEATURE_REPO = os.getenv("FEATURE_REPO_DIR", "/shared/feature_repo")
    
    def main():
        logger.info("=" * 60)
        logger.info("RAY BATCH INFERENCE")
        logger.info("=" * 60)
        logger.info("Production-scale scoring with Feast + Ray")
        logger.info("Ray connection handled by Feast offline_store config")
        logger.info("")
        
        os.makedirs(OUTPUT_PATH, exist_ok=True)
        
        # Load model and scalers
        logger.info("")
        logger.info("Loading model and scalers...")
        
        model_file = f"{MODEL_PATH}/best_model.pt"
        scaler_file = f"{MODEL_PATH}/scalers.joblib"
        
        if not os.path.exists(model_file):
            logger.error(f"Model not found: {model_file}")
            sys.exit(1)
        
        checkpoint = torch.load(model_file, map_location='cpu', weights_only=False)
        scalers = joblib.load(scaler_file)
        
        # Load feature columns from training (ensures consistency)
        feature_cols_file = f"{MODEL_PATH}/feature_cols.pkl"
        if os.path.exists(feature_cols_file):
            feature_cols = joblib.load(feature_cols_file)
        elif isinstance(checkpoint, dict):
            feature_cols = checkpoint.get('feature_columns', [])
        else:
            feature_cols = []
        
        input_dim = len(feature_cols)
        logger.info(f"   Model: {model_file}")
        logger.info(f"   Features: {input_dim}")
        
        # Load entities to score
        logger.info("")
        logger.info("Loading entities to score...")
        
        # Use latest entity data from dataprep
        entities_file = f"{DATA_PATH}/entities.parquet"
        if os.path.exists(entities_file):
            entities_df = pd.read_parquet(entities_file)
            # Rename date to event_timestamp if needed
            if 'date' in entities_df.columns:
                entities_df = entities_df.rename(columns={'date': 'event_timestamp'})
        else:
            # Generate entities for all store/dept combinations
            NUM_STORES = int(os.getenv("NUM_STORES", "45"))
            NUM_DEPTS = int(os.getenv("NUM_DEPTS", "14"))
            
            entities = []
            timestamp = datetime.now(timezone.utc)
            for store_id in range(1, NUM_STORES + 1):
                for dept_id in range(1, NUM_DEPTS + 1):
                    entities.append({
                        "store_id": store_id,
                        "dept_id": dept_id,
                        "event_timestamp": timestamp
                    })
            entities_df = pd.DataFrame(entities)
        
        logger.info(f"   Entities to score: {len(entities_df):,}")
        
        # Load pre-computed features (created by DataPrep)
        # In production, this would use Feast get_online_features for fresh data
        logger.info("")
        logger.info("Loading pre-computed features...")
        
        start_time = time.time()
        features_file = f"{DATA_PATH}/features.parquet"
        features_df = pd.read_parquet(features_file)
        
        # Get latest timestamp for each entity (most recent features)
        if 'date' in features_df.columns:
            features_df = features_df.rename(columns={'date': 'event_timestamp'})
        
        # Get latest features per entity
        features_df = features_df.sort_values('event_timestamp').groupby(['store_id', 'dept_id']).last().reset_index()
        
        feature_time = time.time() - start_time
        logger.info(f"   ✅ Features loaded in {feature_time:.2f}s")
        logger.info(f"   Entities: {len(features_df):,}")
        
        # Prepare for inference
        logger.info("")
        logger.info("Running batch inference...")
        
        # Get feature values (same columns as training)
        missing = [c for c in feature_cols if c not in features_df.columns]
        if missing:
            logger.warning(f"   Missing features (will use 0): {missing}")
            for col in missing:
                features_df[col] = 0
        
        X = features_df[feature_cols].fillna(0).values
        logger.info(f"   Feature columns: {len(feature_cols)}")
        
        # Scale features
        X_scaled = scalers['scaler_X'].transform(X)
        
        # Build model
        class SalesMLP(torch.nn.Module):
            def __init__(self, input_dim, hidden_dims=[512, 256, 128, 64], dropout=0.3):
                super().__init__()
                layers = []
                prev_dim = input_dim
                for dim in hidden_dims:
                    layers.extend([
                        torch.nn.Linear(prev_dim, dim),
                        torch.nn.BatchNorm1d(dim),
                        torch.nn.ReLU(),
                        torch.nn.Dropout(dropout)
                    ])
                    prev_dim = dim
                layers.append(torch.nn.Linear(prev_dim, 1))
                self.net = torch.nn.Sequential(*layers)
            def forward(self, x):
                return self.net(x).squeeze(-1)
        
        model = SalesMLP(input_dim)
        # Model saved as state_dict directly (not wrapped in dict)
        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
        else:
            model.load_state_dict(checkpoint)
        model.eval()
        
        # Run inference
        start_time = time.time()
        with torch.no_grad():
            X_tensor = torch.FloatTensor(X_scaled)
            predictions_scaled = model(X_tensor).numpy().flatten()
        
        # Inverse transform
        predictions = scalers['scaler_y'].inverse_transform(predictions_scaled.reshape(-1, 1)).flatten()
        inference_time = time.time() - start_time
        
        logger.info(f"   ✅ Inference completed in {inference_time:.2f}s")
        logger.info(f"   Throughput: {len(predictions)/inference_time:,.0f} predictions/sec")
        
        # Save results
        logger.info("")
        logger.info("Saving predictions...")
        
        results_df = features_df[['store_id', 'dept_id']].copy()
        if 'event_timestamp' in features_df.columns:
            results_df['timestamp'] = features_df['event_timestamp']
        results_df['predicted_weekly_sales'] = predictions
        results_df['prediction_time'] = datetime.now(timezone.utc)
        
        # Save to parquet
        output_file = f"{OUTPUT_PATH}/batch_predictions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.parquet"
        results_df.to_parquet(output_file, index=False)
        
        # Also save latest
        results_df.to_parquet(f"{OUTPUT_PATH}/latest_predictions.parquet", index=False)
        
        logger.info(f"   Saved: {output_file}")
        logger.info(f"   Predictions: {len(results_df):,}")
        
        # Summary statistics
        logger.info("")
        logger.info("=" * 60)
        logger.info("BATCH INFERENCE COMPLETE")
        logger.info("=" * 60)
        logger.info(f"   Entities scored: {len(results_df):,}")
        logger.info(f"   Feature retrieval: {feature_time:.1f}s")
        logger.info(f"   Model inference: {inference_time:.2f}s")
        logger.info(f"   Total time: {feature_time + inference_time:.1f}s")
        logger.info("")
        logger.info("Prediction summary:")
        logger.info(f"   Min: ${results_df['predicted_weekly_sales'].min():,.0f}")
        logger.info(f"   Max: ${results_df['predicted_weekly_sales'].max():,.0f}")
        logger.info(f"   Mean: ${results_df['predicted_weekly_sales'].mean():,.0f}")
        logger.info(f"   Median: ${results_df['predicted_weekly_sales'].median():,.0f}")
        
        logger.info("Batch inference job complete!")
    
    if __name__ == "__main__":
        main()
---
apiVersion: batch/v1
kind: Job
metadata:
  name: batch-inference
  namespace: feast-trainer-demo
spec:
  backoffLimit: 2
  template:
    spec:
      restartPolicy: Never
      containers:
        - name: batch-inference
          image: registry.redhat.io/rhoai/odh-training-cuda128-torch28-py312-rhel9@sha256:bdc8cb781f005c11534a959fd57b8ba5133522e3bb4756d409e3111eeaf2e8ee
          command: ["/bin/bash", "-c"]
          args:
            - |
              echo "Installing dependencies..."
              pip install -q joblib scikit-learn feast[ray,postgres] psycopg2-binary --target=/tmp/pylibs 2>/dev/null
              export PYTHONPATH=/tmp/pylibs:$PYTHONPATH
              python /scripts/batch_inference.py
          env:
            - name: DATA_PATH
              value: "/shared/data"
            - name: MODEL_PATH
              value: "/shared/models"
            - name: OUTPUT_PATH
              value: "/shared/predictions"
            - name: FEATURE_REPO_DIR
              value: "/shared/feature_repo"
            - name: RAY_ADDRESS
              value: "ray://feast-ray-head-svc.feast-trainer-demo.svc.cluster.local:10001"
            - name: NUM_STORES
              value: "45"
            - name: NUM_DEPTS
              value: "14"
          volumeMounts:
            - name: shared-storage
              mountPath: /shared
            - name: scripts
              mountPath: /scripts
          resources:
            requests:
              memory: "4Gi"
              cpu: "2"
            limits:
              memory: "8Gi"
              cpu: "4"
      volumes:
        - name: shared-storage
          persistentVolumeClaim:
            claimName: feast-pvc
        - name: scripts
          configMap:
            name: batch-inference-scripts

