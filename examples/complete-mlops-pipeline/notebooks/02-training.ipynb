{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sales Forecasting - Distributed Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q kubeflow-training mlflow yamlmagic\n",
        "%load_ext yamlmagic\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%yaml parameters\n",
        "\n",
        "# =============================================================================\n",
        "# Cluster Configuration\n",
        "# =============================================================================\n",
        "namespace: feast-trainer-demo\n",
        "shared_pvc: feast-pvc\n",
        "runtime: torch-distributed\n",
        "\n",
        "# =============================================================================\n",
        "# Training Hyperparameters\n",
        "# =============================================================================\n",
        "epochs: 30\n",
        "batch_size: 256\n",
        "learning_rate: 0.001\n",
        "\n",
        "# =============================================================================\n",
        "# Model Architecture\n",
        "# =============================================================================\n",
        "model:\n",
        "  hidden_dims: [256, 128, 64]\n",
        "  dropout: 0.2\n",
        "\n",
        "# =============================================================================\n",
        "# Feature Columns (must match Feast features)\n",
        "# =============================================================================\n",
        "features:\n",
        "  - lag_1\n",
        "  - lag_2\n",
        "  - lag_4\n",
        "  - lag_8\n",
        "  - lag_52\n",
        "  - rolling_mean_4w\n",
        "  - store_size\n",
        "  - temperature\n",
        "  - fuel_price\n",
        "  - cpi\n",
        "  - unemployment\n",
        "\n",
        "# =============================================================================\n",
        "# Distributed Training (1 worker for quickstart, increase for production)\n",
        "# =============================================================================\n",
        "num_workers: 1\n",
        "resources_per_worker:\n",
        "  cpu: 4\n",
        "  memory: 16Gi\n",
        "  \n",
        "# GPU Configuration: \"none\", \"nvidia\", or \"amd\"\n",
        "gpu_type: nvidia\n",
        "gpu_count: 1\n",
        "\n",
        "# =============================================================================\n",
        "# MLflow Tracking\n",
        "# =============================================================================\n",
        "mlflow:\n",
        "  experiment_name: sales-forecasting\n",
        "\n",
        "# =============================================================================\n",
        "# Data Paths (PVC mounted at /shared)\n",
        "# =============================================================================\n",
        "paths:\n",
        "  data_dir: /shared/data\n",
        "  model_dir: /shared/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract key parameters for convenience\n",
        "NAMESPACE = parameters['namespace']\n",
        "SHARED_PVC = parameters['shared_pvc']\n",
        "RUNTIME = parameters['runtime']\n",
        "MLFLOW_URI = f\"http://mlflow.{NAMESPACE}.svc.cluster.local:5000\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Authentication\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "K8S_TOKEN = os.getenv(\"K8S_TOKEN\", \"<YOUR_TOKEN>\")\n",
        "K8S_API_SERVER = os.getenv(\"K8S_API_SERVER\", \"<YOUR_API_SERVER>\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from kubernetes import client as k8s\n",
        "from kubeflow.training import TrainerClient, CustomTrainer\n",
        "from kubeflow.training.types import KubernetesBackendConfig\n",
        "from kubeflow.training.types import (\n",
        "    PodTemplateOverrides, PodTemplateOverride,\n",
        "    PodSpecOverride, ContainerOverride,\n",
        "    Labels, Annotations\n",
        ")\n",
        "\n",
        "cfg = k8s.Configuration()\n",
        "if K8S_TOKEN and K8S_API_SERVER:\n",
        "    cfg.host = K8S_API_SERVER\n",
        "    cfg.verify_ssl = False\n",
        "    cfg.api_key = {\"authorization\": f\"Bearer {K8S_TOKEN}\"}\n",
        "\n",
        "trainer_client = TrainerClient(\n",
        "    KubernetesBackendConfig(\n",
        "        namespace=NAMESPACE,\n",
        "        client_configuration=cfg if K8S_TOKEN else None\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Runtime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "runtime = trainer_client.get_runtime(RUNTIME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_sales_model(parameters):\n",
        "    \"\"\"\n",
        "    Distributed training function for sales forecasting model.\n",
        "    Supports CPU, NVIDIA GPU (CUDA), and AMD GPU (ROCm).\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import json\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.distributed as dist\n",
        "    import pandas as pd\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from pathlib import Path\n",
        "    from datetime import datetime\n",
        "\n",
        "    # =========================================================================\n",
        "    # Device Detection (CPU / NVIDIA CUDA / AMD ROCm)\n",
        "    # =========================================================================\n",
        "    def detect_device():\n",
        "        \"\"\"Detect available compute device and return (device, backend, device_type)\"\"\"\n",
        "        if torch.cuda.is_available():\n",
        "            # Check if ROCm (AMD) or CUDA (NVIDIA)\n",
        "            is_rocm = hasattr(torch.version, 'hip') and torch.version.hip is not None\n",
        "            device_type = \"rocm\" if is_rocm else \"cuda\"\n",
        "            backend = \"nccl\"  # nccl works for both CUDA and ROCm\n",
        "            local_rank = int(os.getenv(\"LOCAL_RANK\", 0))\n",
        "            torch.cuda.set_device(local_rank)\n",
        "            device = torch.device(\"cuda\", local_rank)\n",
        "            return device, backend, device_type\n",
        "        else:\n",
        "            return torch.device(\"cpu\"), \"gloo\", \"cpu\"\n",
        "    \n",
        "    device, backend, device_type = detect_device()\n",
        "\n",
        "    # =========================================================================\n",
        "    # Distributed Setup\n",
        "    # =========================================================================\n",
        "    dist.init_process_group(backend=backend)\n",
        "    rank = dist.get_rank()\n",
        "    world_size = dist.get_world_size()\n",
        "    \n",
        "    if rank == 0:\n",
        "        gpu_info = \"\"\n",
        "        if device_type != \"cpu\":\n",
        "            gpu_name = torch.cuda.get_device_name(0)\n",
        "            gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "            gpu_info = f\" ({gpu_name}, {gpu_mem:.1f}GB)\"\n",
        "        print(f\"Device: {device_type.upper()}{gpu_info} | Workers: {world_size}\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # Configuration\n",
        "    # =========================================================================\n",
        "    mlflow_uri = os.getenv(\"MLFLOW_TRACKING_URI\", \"http://mlflow:5000\")\n",
        "    data_dir = parameters.get('paths', {}).get('data_dir', '/shared/data')\n",
        "    model_dir = parameters.get('paths', {}).get('model_dir', '/shared/models')\n",
        "    epochs = parameters.get('epochs', 50)\n",
        "    batch_size = parameters.get('batch_size', 256)\n",
        "    lr = parameters.get('learning_rate', 0.001)\n",
        "    feature_cols = parameters.get('features', [])\n",
        "    hidden_dims = parameters.get('model', {}).get('hidden_dims', [256, 128, 64])\n",
        "    dropout = parameters.get('model', {}).get('dropout', 0.2)\n",
        "\n",
        "    # =========================================================================\n",
        "    # Model Definition\n",
        "    # =========================================================================\n",
        "    class SalesMLP(nn.Module):\n",
        "        def __init__(self, input_dim, hidden_dims, dropout):\n",
        "            super().__init__()\n",
        "            layers = []\n",
        "            prev_dim = input_dim\n",
        "            for h_dim in hidden_dims:\n",
        "                layers.extend([\n",
        "                    nn.Linear(prev_dim, h_dim),\n",
        "                    nn.BatchNorm1d(h_dim),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Dropout(dropout),\n",
        "                ])\n",
        "                prev_dim = h_dim\n",
        "            layers.append(nn.Linear(prev_dim, 1))\n",
        "            self.net = nn.Sequential(*layers)\n",
        "        \n",
        "        def forward(self, x):\n",
        "            return self.net(x).squeeze(-1)\n",
        "\n",
        "    # =========================================================================\n",
        "    # Load Data\n",
        "    # =========================================================================\n",
        "    df = pd.read_parquet(f\"{data_dir}/features.parquet\")\n",
        "    available_features = [c for c in feature_cols if c in df.columns]\n",
        "    df = df.dropna(subset=available_features + [\"weekly_sales\"])\n",
        "    X = df[available_features].values\n",
        "    y = df[\"weekly_sales\"].values\n",
        "    \n",
        "    if rank == 0:\n",
        "        print(f\"Data: {len(df):,} samples, {len(available_features)} features\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # Preprocessing\n",
        "    # =========================================================================\n",
        "    scaler_X = StandardScaler()\n",
        "    scaler_y = StandardScaler()\n",
        "    X_scaled = scaler_X.fit_transform(X)\n",
        "    y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "    # =========================================================================\n",
        "    # Model + DDP\n",
        "    # =========================================================================\n",
        "    model = SalesMLP(len(available_features), hidden_dims, dropout).to(device)\n",
        "    if world_size > 1:\n",
        "        model = nn.parallel.DistributedDataParallel(model, device_ids=[device.index] if device_type != \"cpu\" else None)\n",
        "    \n",
        "    train_dataset = torch.utils.data.TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
        "    sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
        "    \n",
        "    X_test_tensor = torch.FloatTensor(X_test).to(device)\n",
        "    y_test_tensor = torch.FloatTensor(y_test).to(device)\n",
        "    \n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    \n",
        "    best_loss = float('inf')\n",
        "    best_state = None\n",
        "\n",
        "    # =========================================================================\n",
        "    # MLflow (rank 0)\n",
        "    # =========================================================================\n",
        "    if rank == 0:\n",
        "        try:\n",
        "            import mlflow\n",
        "            os.environ[\"MLFLOW_TRACKING_URI\"] = mlflow_uri\n",
        "            exp_name = parameters.get('mlflow', {}).get('experiment_name', 'sales-forecasting')\n",
        "            run_name = os.getenv(\"RUN_NAME\", f\"sales-{datetime.now().strftime('%m%d-%H%M')}\")\n",
        "            mlflow.set_experiment(exp_name)\n",
        "            mlflow.start_run(run_name=run_name)\n",
        "            mlflow.log_params({\n",
        "                \"epochs\": epochs, \"batch_size\": batch_size, \"learning_rate\": lr,\n",
        "                \"world_size\": world_size, \"device_type\": device_type,\n",
        "                \"hidden_dims\": hidden_dims, \"dropout\": dropout\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"MLflow: {e}\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # Training Loop\n",
        "    # =========================================================================\n",
        "    for epoch in range(epochs):\n",
        "        sampler.set_epoch(epoch)\n",
        "        model.train()\n",
        "        \n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model(X_batch), y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        scheduler.step()\n",
        "        \n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            test_loss = criterion(model(X_test_tensor), y_test_tensor).item()\n",
        "        \n",
        "        if test_loss < best_loss:\n",
        "            best_loss = test_loss\n",
        "            if rank == 0:\n",
        "                base_model = model.module if hasattr(model, 'module') else model\n",
        "                best_state = base_model.state_dict().copy()\n",
        "        \n",
        "        if rank == 0 and (epoch + 1) % 10 == 0:\n",
        "            print(f\"Epoch {epoch+1}/{epochs} | Loss: {test_loss:.6f} | Best: {best_loss:.6f}\")\n",
        "            try: mlflow.log_metrics({\"val_loss\": test_loss, \"best_loss\": best_loss}, step=epoch)\n",
        "            except: pass\n",
        "\n",
        "    # =========================================================================\n",
        "    # Save Model (rank 0)\n",
        "    # =========================================================================\n",
        "    dist.barrier()\n",
        "    \n",
        "    if rank == 0:\n",
        "        import joblib\n",
        "        Path(model_dir).mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        torch.save(best_state, f\"{model_dir}/best_model.pt\")\n",
        "        joblib.dump({\"scaler_X\": scaler_X, \"scaler_y\": scaler_y, \"feature_cols\": available_features}, f\"{model_dir}/scalers.joblib\")\n",
        "        \n",
        "        with open(f\"{model_dir}/model_metadata.json\", \"w\") as f:\n",
        "            json.dump({\n",
        "                \"input_dim\": len(available_features),\n",
        "                \"hidden_dims\": hidden_dims,\n",
        "                \"feature_columns\": available_features,\n",
        "                \"best_loss\": best_loss,\n",
        "                \"device_type\": device_type\n",
        "            }, f, indent=2)\n",
        "        \n",
        "        try:\n",
        "            mlflow.log_metric(\"best_loss\", best_loss)\n",
        "            mlflow.log_artifacts(model_dir)\n",
        "            mlflow.end_run()\n",
        "        except: pass\n",
        "        \n",
        "        print(f\"Done! Best loss: {best_loss:.6f} | Model: {model_dir}\")\n",
        "    \n",
        "    dist.barrier()\n",
        "    dist.destroy_process_group()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Submit Training Job\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "job_id = datetime.now().strftime(\"%m%d-%H%M\")\n",
        "job_name = f\"sales-training-{job_id}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build resource spec based on GPU type\n",
        "resources = {\n",
        "    \"cpu\": parameters['resources_per_worker']['cpu'],\n",
        "    \"memory\": parameters['resources_per_worker']['memory'],\n",
        "}\n",
        "\n",
        "gpu_type = parameters.get('gpu_type', 'none')\n",
        "gpu_count = parameters.get('gpu_count', 0)\n",
        "\n",
        "if gpu_type == 'nvidia' and gpu_count > 0:\n",
        "    resources[\"nvidia.com/gpu\"] = gpu_count\n",
        "elif gpu_type == 'amd' and gpu_count > 0:\n",
        "    resources[\"amd.com/gpu\"] = gpu_count\n",
        "\n",
        "# Submit job\n",
        "job = trainer_client.train(\n",
        "    trainer=CustomTrainer(\n",
        "        func=train_sales_model,\n",
        "        num_nodes=parameters['num_workers'],\n",
        "        resources_per_node=resources,\n",
        "        packages_to_install=[\"scikit-learn\", \"pandas\", \"pyarrow\", \"joblib\", \"mlflow\", \"matplotlib\"],\n",
        "        env={\"MLFLOW_TRACKING_URI\": MLFLOW_URI, \"RUN_NAME\": f\"sales-forecast-{job_id}\"},\n",
        "    ),\n",
        "    runtime=runtime,\n",
        "    parameters=parameters,\n",
        "    options=[\n",
        "        Labels({\"app\": \"sales-forecasting\", \"job-type\": \"training\", \"run-id\": job_id}),\n",
        "        Annotations({\"description\": f\"Sales forecasting - {job_id}\"}),\n",
        "        PodTemplateOverrides(\n",
        "            PodTemplateOverride(\n",
        "                target_jobs=[\"node\"],\n",
        "                spec=PodSpecOverride(\n",
        "                    volumes=[{\"name\": \"shared\", \"persistentVolumeClaim\": {\"claimName\": SHARED_PVC}}],\n",
        "                    containers=[ContainerOverride(name=\"node\", volume_mounts=[{\"name\": \"shared\", \"mountPath\": \"/shared\"}])]\n",
        "                )\n",
        "            )\n",
        "        ),\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Monitor Progress\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_client.wait_for_job_status(name=job, status={\"Running\"}, timeout=300)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_ = trainer_client.get_job_logs(name=job, follow=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_client.wait_for_job_status(name=job, status={\"Complete\", \"Failed\"}, timeout=3600)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MLflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mlflow\n",
        "\n",
        "mlflow.set_tracking_uri(MLFLOW_URI)\n",
        "experiment = mlflow.get_experiment_by_name(parameters['mlflow']['experiment_name'])\n",
        "runs = mlflow.search_runs(\n",
        "    experiment_ids=[experiment.experiment_id],\n",
        "    max_results=5,\n",
        "    order_by=[\"start_time DESC\"]\n",
        ")\n",
        "runs[[\"tags.mlflow.runName\", \"metrics.best_loss\"]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleanup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# trainer_client.delete_job(name=job)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
