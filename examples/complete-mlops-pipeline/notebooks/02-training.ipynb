{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 - Kubeflow Training with Feast Integration\n",
        "\n",
        "**TrainJob â†’ Feast â†’ PyTorch DDP â†’ MLflow**\n",
        "\n",
        "## Configuration Options\n",
        "\n",
        "| Mode | `use_ray` | `get_historical_features()` | Dependencies |\n",
        "|------|-----------|------------------------------|--------------|\n",
        "| **Simple** | `false` | File-based (single node) | `feast[postgres]` |\n",
        "| **Distributed** | `true` | KubeRay (parallel PIT joins) | `feast[ray,postgres]`, `codeflare-sdk` |\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚                     TRAINJOB POD                            â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚                                                             â”‚\n",
        "â”‚  training_df = store.get_historical_features(               â”‚\n",
        "â”‚      entity_df, features=training_features                  â”‚\n",
        "â”‚  ).to_df()                                                  â”‚\n",
        "â”‚           â”‚                                                 â”‚\n",
        "â”‚           â”œâ”€â”€ use_ray=false â†’ File offline store (local)    â”‚\n",
        "â”‚           â”‚                                                 â”‚\n",
        "â”‚           â””â”€â”€ use_ray=true  â†’ KubeRay cluster (distributed) â”‚\n",
        "â”‚                                      â”‚                      â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                                       â–¼\n",
        "                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "                          â”‚   KUBERAY CLUSTER   â”‚\n",
        "                          â”‚  (if use_ray=true)  â”‚\n",
        "                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q kubeflow-training \"mlflow>=3.0\" yamlmagic\n",
        "%load_ext yamlmagic\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%yaml parameters\n",
        "\n",
        "# =============================================================================\n",
        "# ðŸ”€ MODE SELECTION - Must match 01-feast-features.ipynb\n",
        "# =============================================================================\n",
        "use_ray: true  # true = KubeRay for distributed training, false = file-based only\n",
        "\n",
        "# =============================================================================\n",
        "# Cluster\n",
        "# =============================================================================\n",
        "namespace: feast-trainer-demo\n",
        "shared_pvc: feast-pvc\n",
        "runtime: torch-distributed  # Use built-in supported runtime (PVC added via PodTemplateOverrides)\n",
        "\n",
        "# =============================================================================\n",
        "# KubeRay Configuration (only used if use_ray: true)\n",
        "# =============================================================================\n",
        "kuberay:\n",
        "  cluster_name: feast-ray\n",
        "  skip_tls: true\n",
        "\n",
        "# =============================================================================\n",
        "# Training Hyperparameters\n",
        "# =============================================================================\n",
        "epochs: 30\n",
        "batch_size: 64\n",
        "learning_rate: 0.0005\n",
        "weight_decay: 0.001\n",
        "\n",
        "# =============================================================================\n",
        "# Model Architecture\n",
        "# =============================================================================\n",
        "model:\n",
        "  hidden_dims: [512, 256, 128, 64]\n",
        "  dropout: 0.3\n",
        "\n",
        "# =============================================================================\n",
        "# Distributed Training\n",
        "# =============================================================================\n",
        "num_workers: 1\n",
        "resources:\n",
        "  cpu: 4\n",
        "  memory: 8Gi\n",
        "gpu_type: nvidia  # none, nvidia, amd\n",
        "gpu_count: 1\n",
        "\n",
        "# =============================================================================\n",
        "# MLflow\n",
        "# =============================================================================\n",
        "mlflow_experiment: sales-forecasting\n",
        "\n",
        "# =============================================================================\n",
        "# Paths (PVC mounted at /shared)\n",
        "# =============================================================================\n",
        "paths:\n",
        "  data: /shared/data\n",
        "  models: /shared/models\n",
        "  feature_repo: /shared/feature_repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Derived\n",
        "parameters['mlflow_uri'] = f\"http://mlflow.{parameters['namespace']}.svc.cluster.local:5000\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Authentication\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "K8S_TOKEN = os.getenv(\"K8S_TOKEN\", \"<YOUR_TOKEN>\")\n",
        "K8S_API_SERVER = os.getenv(\"K8S_API_SERVER\", \"<YOUR_API_SERVER>\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from kubernetes import client as k8s\n",
        "from kubeflow.training import TrainerClient, CustomTrainer\n",
        "from kubeflow.training.types import KubernetesBackendConfig\n",
        "from kubeflow.training.types import (\n",
        "    PodTemplateOverrides, PodTemplateOverride,\n",
        "    PodSpecOverride, ContainerOverride,\n",
        "    Labels, Annotations\n",
        ")\n",
        "\n",
        "cfg = k8s.Configuration()\n",
        "if K8S_TOKEN and K8S_API_SERVER:\n",
        "    cfg.host = K8S_API_SERVER\n",
        "    cfg.verify_ssl = False\n",
        "    cfg.api_key = {\"authorization\": f\"Bearer {K8S_TOKEN}\"}\n",
        "\n",
        "trainer_client = TrainerClient(\n",
        "    KubernetesBackendConfig(\n",
        "        namespace=parameters['namespace'],\n",
        "        client_configuration=cfg if K8S_TOKEN else None\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Runtime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "runtime = trainer_client.get_runtime(parameters['runtime'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_sales_model(parameters):\n",
        "    \"\"\"\n",
        "    Distributed training with FEAST INTEGRATION.\n",
        "    \n",
        "    KEY PATTERN: This function runs INSIDE the TrainJob pod and calls\n",
        "    Feast directly to get training data. This ensures feature consistency\n",
        "    between training and inference.\n",
        "    \n",
        "    Flow:\n",
        "    1. Load Feast FeatureStore from shared PVC\n",
        "    2. Call get_historical_features() with training_features service\n",
        "    3. Train PyTorch model with DDP\n",
        "    4. Log to MLflow\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import json\n",
        "    import numpy as np\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.distributed as dist\n",
        "    from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "    from torch.utils.data import DataLoader, Dataset, DistributedSampler\n",
        "    import pandas as pd\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from pathlib import Path\n",
        "    from datetime import datetime, timezone, timedelta\n",
        "    import joblib\n",
        "\n",
        "    # =========================================================================\n",
        "    # Device Setup\n",
        "    # =========================================================================\n",
        "    backend = 'nccl' if torch.cuda.is_available() else 'gloo'\n",
        "    dist.init_process_group(backend=backend)\n",
        "    rank, world_size = dist.get_rank(), dist.get_world_size()\n",
        "    local_rank = int(os.environ.get(\"LOCAL_RANK\", 0))\n",
        "    device = torch.device(f\"cuda:{local_rank}\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    if rank == 0:\n",
        "        print(f\"DDP: rank={rank}/{world_size}, device={device}\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # Configuration\n",
        "    # =========================================================================\n",
        "    mlflow_uri = os.getenv(\"MLFLOW_TRACKING_URI\", \"http://mlflow:5000\")\n",
        "    data_dir = parameters.get('paths', {}).get('data', '/shared/data')\n",
        "    model_dir = parameters.get('paths', {}).get('models', '/shared/models')\n",
        "    feature_repo = parameters.get('paths', {}).get('feature_repo', '/shared/feature_repo')\n",
        "    epochs = parameters.get('epochs', 30)\n",
        "    batch_size = parameters.get('batch_size', 64)\n",
        "    lr = parameters.get('learning_rate', 0.0005)\n",
        "    weight_decay = parameters.get('weight_decay', 0.001)\n",
        "    hidden_dims = parameters.get('model', {}).get('hidden_dims', [512, 256, 128, 64])\n",
        "    dropout = parameters.get('model', {}).get('dropout', 0.3)\n",
        "\n",
        "    # =========================================================================\n",
        "    # Model Definition\n",
        "    # =========================================================================\n",
        "    class SalesMLP(nn.Module):\n",
        "        def __init__(self, input_dim, hidden_dims, dropout):\n",
        "            super().__init__()\n",
        "            layers = []\n",
        "            prev_dim = input_dim\n",
        "            for h_dim in hidden_dims:\n",
        "                layers.extend([\n",
        "                    nn.Linear(prev_dim, h_dim),\n",
        "                    nn.BatchNorm1d(h_dim),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Dropout(dropout),\n",
        "                ])\n",
        "                prev_dim = h_dim\n",
        "            layers.append(nn.Linear(prev_dim, 1))\n",
        "            self.net = nn.Sequential(*layers)\n",
        "        \n",
        "        def forward(self, x):\n",
        "            return self.net(x).squeeze(-1)\n",
        "    \n",
        "    class SalesDataset(Dataset):\n",
        "        def __init__(self, X, y):\n",
        "            self.X = torch.tensor(X, dtype=torch.float32)\n",
        "            self.y = torch.tensor(y, dtype=torch.float32)\n",
        "        def __len__(self): return len(self.X)\n",
        "        def __getitem__(self, i): return self.X[i], self.y[i]\n",
        "\n",
        "    # =========================================================================\n",
        "    # MLflow Setup (rank 0)\n",
        "    # =========================================================================\n",
        "    if rank == 0:\n",
        "        import mlflow\n",
        "        mlflow.set_tracking_uri(mlflow_uri)\n",
        "        mlflow.set_experiment(parameters.get('mlflow_experiment', 'sales-forecasting'))\n",
        "        run = mlflow.start_run(run_name=f\"train-{datetime.now().strftime('%Y%m%d-%H%M%S')}\")\n",
        "        print(f\"MLflow tracking URI: {mlflow_uri}\")\n",
        "        print(f\"MLflow run ID: {run.info.run_id}\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # FEAST: get_historical_features() - File-based or KubeRay (distributed)\n",
        "    # =========================================================================\n",
        "    if rank == 0:\n",
        "        os.makedirs(model_dir, exist_ok=True)\n",
        "        use_ray = parameters.get('use_ray', False)\n",
        "        \n",
        "        print(\"=\" * 60)\n",
        "        if use_ray:\n",
        "            print(\"ðŸ• FEAST + KUBERAY: Distributed get_historical_features()\")\n",
        "        else:\n",
        "            print(\"ðŸ• FEAST: File-based get_historical_features()\")\n",
        "        print(\"=\" * 60)\n",
        "        \n",
        "        # Setup Ray configuration (only if use_ray=true)\n",
        "        if use_ray:\n",
        "            os.environ[\"FEAST_RAY_USE_KUBERAY\"] = \"true\"\n",
        "            os.environ[\"FEAST_RAY_CLUSTER_NAME\"] = parameters.get('kuberay', {}).get('cluster_name', 'feast-ray')\n",
        "            os.environ[\"FEAST_RAY_NAMESPACE\"] = parameters.get('namespace', 'feast-trainer-demo')\n",
        "            os.environ[\"FEAST_RAY_SKIP_TLS\"] = str(parameters.get('kuberay', {}).get('skip_tls', True)).lower()\n",
        "            \n",
        "            # In-cluster auth for CodeFlare SDK\n",
        "            sa_token_path = \"/var/run/secrets/kubernetes.io/serviceaccount/token\"\n",
        "            if os.path.exists(sa_token_path):\n",
        "                with open(sa_token_path) as f:\n",
        "                    os.environ[\"FEAST_RAY_AUTH_TOKEN\"] = f.read()\n",
        "                os.environ[\"FEAST_RAY_AUTH_SERVER\"] = f\"https://{os.environ.get('KUBERNETES_SERVICE_HOST')}:{os.environ.get('KUBERNETES_SERVICE_PORT')}\"\n",
        "                print(\"ðŸ” CodeFlare SDK auth configured (in-cluster)\")\n",
        "            \n",
        "            # Copy Ray config to feature_store.yaml (same pattern as manifest)\n",
        "            import shutil\n",
        "            ray_config = f\"{feature_repo}/feature_store_ray.yaml\"\n",
        "            target_config = f\"{feature_repo}/feature_store.yaml\"\n",
        "            if os.path.exists(ray_config):\n",
        "                shutil.copy(ray_config, target_config)\n",
        "                print(f\"ðŸ“„ Using Ray config: {ray_config}\")\n",
        "        else:\n",
        "            print(\"â„¹ï¸  Using file-based offline store (no KubeRay)\")\n",
        "        \n",
        "        from feast import FeatureStore\n",
        "        store = FeatureStore(repo_path=feature_repo)\n",
        "        print(f\"Loaded Feast from: {feature_repo}\")\n",
        "        \n",
        "        # Create entity DataFrame\n",
        "        entity_rows = []\n",
        "        base_date = datetime(2010, 2, 5, tzinfo=timezone.utc)  # Walmart dataset start\n",
        "        NUM_WEEKS, NUM_STORES, NUM_DEPTS = 104, 10, 5\n",
        "        \n",
        "        for week in range(NUM_WEEKS):\n",
        "            event_ts = base_date + timedelta(weeks=week)\n",
        "            for store_id in range(1, NUM_STORES + 1):\n",
        "                for dept_id in range(1, NUM_DEPTS + 1):\n",
        "                    entity_rows.append({\"store_id\": store_id, \"dept_id\": dept_id, \"event_timestamp\": event_ts})\n",
        "        \n",
        "        entity_df = pd.DataFrame(entity_rows)\n",
        "        print(f\"Entity DataFrame: {len(entity_df):,} rows\")\n",
        "        \n",
        "        # =====================================================================\n",
        "        # KEY CALL: get_historical_features() with Feature Service\n",
        "        # This retrieves the SAME features that inference will use\n",
        "        # =====================================================================\n",
        "        import time\n",
        "        start_time = time.time()\n",
        "        \n",
        "        feature_service = store.get_feature_service(\"training_features\")\n",
        "        print(f\"Using Feature Service: {feature_service.name}\")\n",
        "        \n",
        "        training_data = store.get_historical_features(\n",
        "            entity_df=entity_df,\n",
        "            features=feature_service,\n",
        "        )\n",
        "        training_df = training_data.to_df()\n",
        "        elapsed = time.time() - start_time\n",
        "        \n",
        "        print(f\"âœ… Feast returned {len(training_df):,} rows in {elapsed:.2f}s\")\n",
        "        print(f\"   Throughput: {len(entity_df)/elapsed:.0f} rows/sec\")\n",
        "        \n",
        "        # Temporal split (80/20)\n",
        "        training_df = training_df.dropna(subset=[\"weekly_sales\"])\n",
        "        training_df = training_df.sort_values(\"event_timestamp\")\n",
        "        split_idx = int(len(training_df) * 0.8)\n",
        "        train_df = training_df.iloc[:split_idx]\n",
        "        val_df = training_df.iloc[split_idx:]\n",
        "        \n",
        "        print(f\"Train: {len(train_df):,}, Val: {len(val_df):,}\")\n",
        "        \n",
        "        # Feature columns (exclude identifiers and target)\n",
        "        exclude_cols = [\"store_id\", \"dept_id\", \"date\", \"event_timestamp\", \"weekly_sales\"]\n",
        "        feature_cols = [c for c in training_df.columns \n",
        "                        if c not in exclude_cols\n",
        "                        and training_df[c].dtype in [np.float64, np.int64, np.float32, np.int32]]\n",
        "        \n",
        "        print(f\"Feature columns ({len(feature_cols)}): {feature_cols}\")\n",
        "        \n",
        "        X_train = train_df[feature_cols].fillna(0).values\n",
        "        y_train = train_df[\"weekly_sales\"].values\n",
        "        X_val = val_df[feature_cols].fillna(0).values\n",
        "        y_val = val_df[\"weekly_sales\"].values\n",
        "        \n",
        "        # Scale features\n",
        "        scaler = StandardScaler()\n",
        "        X_train = scaler.fit_transform(X_train)\n",
        "        X_val = scaler.transform(X_val)\n",
        "        \n",
        "        y_scaler = StandardScaler()\n",
        "        y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
        "        y_val_scaled = y_scaler.transform(y_val.reshape(-1, 1)).flatten()\n",
        "        \n",
        "        # Save scalers\n",
        "        joblib.dump(scaler, f\"{model_dir}/scaler.pkl\")\n",
        "        joblib.dump(y_scaler, f\"{model_dir}/y_scaler.pkl\")\n",
        "        joblib.dump(feature_cols, f\"{model_dir}/feature_cols.pkl\")\n",
        "        joblib.dump({\"scaler_X\": scaler, \"scaler_y\": y_scaler}, f\"{model_dir}/scalers.joblib\")\n",
        "        \n",
        "        # Save for other ranks\n",
        "        np.save(f\"{model_dir}/.X_train.npy\", X_train)\n",
        "        np.save(f\"{model_dir}/.y_train.npy\", y_train_scaled)\n",
        "        np.save(f\"{model_dir}/.X_val.npy\", X_val)\n",
        "        np.save(f\"{model_dir}/.y_val.npy\", y_val_scaled)\n",
        "        np.save(f\"{model_dir}/.y_val_orig.npy\", y_val)\n",
        "        np.save(f\"{model_dir}/.input_dim.npy\", np.array([X_train.shape[1]]))\n",
        "        \n",
        "        # Log to MLflow\n",
        "        mlflow.log_params({\n",
        "            \"epochs\": epochs, \"batch_size\": batch_size, \"learning_rate\": lr,\n",
        "            \"weight_decay\": weight_decay, \"hidden_dims\": str(hidden_dims),\n",
        "            \"dropout\": dropout, \"world_size\": world_size,\n",
        "            \"train_rows\": len(train_df), \"val_rows\": len(val_df),\n",
        "            \"input_dim\": X_train.shape[1], \"feature_service\": \"training_features\",\n",
        "        })\n",
        "        \n",
        "        print(\"Data loading and preprocessing complete\")\n",
        "    \n",
        "    dist.barrier()\n",
        "    \n",
        "    # Load data on all ranks\n",
        "    X_train = np.load(f\"{model_dir}/.X_train.npy\")\n",
        "    y_train = np.load(f\"{model_dir}/.y_train.npy\")\n",
        "    X_val = np.load(f\"{model_dir}/.X_val.npy\")\n",
        "    y_val = np.load(f\"{model_dir}/.y_val.npy\")\n",
        "    y_val_orig = np.load(f\"{model_dir}/.y_val_orig.npy\")\n",
        "    input_dim = int(np.load(f\"{model_dir}/.input_dim.npy\")[0])\n",
        "    \n",
        "    dist.barrier()\n",
        "\n",
        "    # =========================================================================\n",
        "    # Training\n",
        "    # =========================================================================\n",
        "    print(f\"[Rank {rank}] Training...\")\n",
        "    \n",
        "    train_ds = SalesDataset(X_train, y_train)\n",
        "    val_ds = SalesDataset(X_val, y_val)\n",
        "    sampler = DistributedSampler(train_ds, num_replicas=world_size, rank=rank)\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, sampler=sampler, num_workers=2)\n",
        "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "    \n",
        "    model = SalesMLP(input_dim, hidden_dims, dropout).to(device)\n",
        "    model = DDP(model, device_ids=[local_rank] if torch.cuda.is_available() else None)\n",
        "    \n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=3)\n",
        "    criterion = nn.MSELoss()\n",
        "    \n",
        "    best_val_loss = float('inf')\n",
        "    best_mape = float('inf')\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        sampler.set_epoch(epoch)\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        \n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(X_batch)\n",
        "            loss = criterion(output, y_batch)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "        \n",
        "        train_loss /= len(train_loader)\n",
        "        \n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        predictions, actuals = [], []\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in val_loader:\n",
        "                output = model(X_batch.to(device))\n",
        "                val_loss += criterion(output, y_batch.to(device)).item()\n",
        "                predictions.extend(output.cpu().numpy())\n",
        "                actuals.extend(y_batch.numpy())\n",
        "        \n",
        "        val_loss /= len(val_loader)\n",
        "        scheduler.step(val_loss)\n",
        "        \n",
        "        if rank == 0:\n",
        "            predictions = np.array(predictions)\n",
        "            y_scaler = joblib.load(f\"{model_dir}/y_scaler.pkl\")\n",
        "            preds_orig = y_scaler.inverse_transform(predictions.reshape(-1, 1)).flatten()\n",
        "            \n",
        "            mask = np.abs(y_val_orig) > 1000\n",
        "            mape = np.mean(np.abs((y_val_orig[mask] - preds_orig[mask]) / y_val_orig[mask])) * 100 if mask.sum() > 0 else np.nan\n",
        "            rmse = np.sqrt(np.mean((y_val_orig - preds_orig) ** 2))\n",
        "            mae = np.mean(np.abs(y_val_orig - preds_orig))\n",
        "            \n",
        "            mlflow.log_metrics({\n",
        "                \"train_loss\": train_loss, \"val_loss\": val_loss,\n",
        "                \"mape\": mape, \"rmse\": rmse, \"mae\": mae,\n",
        "                \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
        "            }, step=epoch)\n",
        "            \n",
        "            print(f\"Epoch {epoch+1}/{epochs} | Train: {train_loss:.4f} | Val: {val_loss:.4f} | MAPE: {mape:.1f}% | RMSE: {rmse:.0f}\")\n",
        "            \n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_mape = mape\n",
        "                torch.save(model.module.state_dict(), f\"{model_dir}/best_model.pt\")\n",
        "                print(\"  â†’ Saved best model\")\n",
        "        \n",
        "        dist.barrier()\n",
        "    \n",
        "    # =========================================================================\n",
        "    # Save Model (rank 0)\n",
        "    # =========================================================================\n",
        "    dist.barrier()\n",
        "    \n",
        "    if rank == 0:\n",
        "        mlflow.log_metrics({\"best_val_loss\": best_val_loss, \"best_mape\": best_mape})\n",
        "        \n",
        "        # Load best model for logging\n",
        "        best_model = SalesMLP(input_dim, hidden_dims, dropout)\n",
        "        best_model.load_state_dict(torch.load(f\"{model_dir}/best_model.pt\"))\n",
        "        best_model.eval()\n",
        "        \n",
        "        # Log model to MLflow\n",
        "        model_info = mlflow.pytorch.log_model(\n",
        "            best_model, artifact_path=\"model\",\n",
        "            pip_requirements=[\"torch>=2.0\", \"numpy\", \"scikit-learn\"],\n",
        "        )\n",
        "        \n",
        "        # Register model\n",
        "        try:\n",
        "            model_uri = f\"runs:/{mlflow.active_run().info.run_id}/model\"\n",
        "            mlflow.register_model(model_uri, \"sales-forecasting-mlp\")\n",
        "            print(\"Model registered in MLflow Model Registry\")\n",
        "        except Exception as e:\n",
        "            print(f\"Model registration skipped: {e}\")\n",
        "        \n",
        "        # Log artifacts\n",
        "        mlflow.log_artifact(f\"{model_dir}/scaler.pkl\", artifact_path=\"preprocessing\")\n",
        "        mlflow.log_artifact(f\"{model_dir}/y_scaler.pkl\", artifact_path=\"preprocessing\")\n",
        "        mlflow.log_artifact(f\"{model_dir}/feature_cols.pkl\", artifact_path=\"preprocessing\")\n",
        "        \n",
        "        # Model metadata\n",
        "        with open(f\"{model_dir}/model_metadata.json\", \"w\") as f:\n",
        "            json.dump({\n",
        "                \"model_type\": \"SalesMLP\", \"input_dim\": input_dim,\n",
        "                \"hidden_dims\": hidden_dims, \"dropout\": dropout,\n",
        "                \"best_mape\": float(best_mape), \"best_val_loss\": float(best_val_loss),\n",
        "            }, f, indent=2)\n",
        "        mlflow.log_artifact(f\"{model_dir}/model_metadata.json\")\n",
        "        \n",
        "        mlflow.end_run()\n",
        "        \n",
        "        # Cleanup temp files\n",
        "        for f in [\".X_train.npy\", \".y_train.npy\", \".X_val.npy\", \".y_val.npy\", \".y_val_orig.npy\", \".input_dim.npy\"]:\n",
        "            try: os.remove(f\"{model_dir}/{f}\")\n",
        "            except: pass\n",
        "        \n",
        "        print(\"=\" * 60)\n",
        "        print(f\"âœ… TRAINING COMPLETE!\")\n",
        "        print(f\"   Best val_loss: {best_val_loss:.4f}\")\n",
        "        print(f\"   Best MAPE: {best_mape:.1f}%\")\n",
        "        print(f\"   Model saved to: {model_dir}/best_model.pt\")\n",
        "        print(\"=\" * 60)\n",
        "    \n",
        "    dist.barrier()\n",
        "    dist.destroy_process_group()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Submit Training Job\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "job_id = datetime.now().strftime(\"%m%d-%H%M\")\n",
        "job_name = f\"sales-training-{job_id}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPU resources\n",
        "resources = {**parameters['resources']}\n",
        "if parameters['gpu_type'] == 'nvidia' and parameters['gpu_count'] > 0:\n",
        "    resources[\"nvidia.com/gpu\"] = parameters['gpu_count']\n",
        "elif parameters['gpu_type'] == 'amd' and parameters['gpu_count'] > 0:\n",
        "    resources[\"amd.com/gpu\"] = parameters['gpu_count']\n",
        "\n",
        "# Packages: include Ray dependencies only if use_ray is true\n",
        "base_packages = [\"scikit-learn\", \"pandas\", \"pyarrow\", \"joblib\", \"mlflow>=3.0\"]\n",
        "if parameters.get('use_ray', False):\n",
        "    packages = [\"feast[ray,postgres]==0.59.0\", \"codeflare-sdk\"] + base_packages\n",
        "    description = f\"Sales forecasting with Feast+KubeRay - {job_id}\"\n",
        "else:\n",
        "    packages = [\"feast[postgres]==0.59.0\"] + base_packages\n",
        "    description = f\"Sales forecasting with Feast (file-based) - {job_id}\"\n",
        "\n",
        "# Submit training job\n",
        "job = trainer_client.train(\n",
        "    trainer=CustomTrainer(\n",
        "        func=train_sales_model,\n",
        "        num_nodes=parameters['num_workers'],\n",
        "        resources_per_node=resources,\n",
        "        packages_to_install=packages,\n",
        "        env={\n",
        "            \"MLFLOW_TRACKING_URI\": parameters['mlflow_uri'],\n",
        "            \"RUN_NAME\": f\"sales-forecast-{job_id}\",\n",
        "        },\n",
        "    ),\n",
        "    runtime=runtime,\n",
        "    parameters=parameters,\n",
        "    options=[\n",
        "        Labels({\"app\": \"sales-forecasting\", \"run-id\": job_id}),\n",
        "        Annotations({\"description\": description}),\n",
        "        PodTemplateOverrides(\n",
        "            PodTemplateOverride(\n",
        "                target_jobs=[\"node\"],\n",
        "                spec=PodSpecOverride(\n",
        "                    volumes=[{\"name\": \"shared\", \"persistentVolumeClaim\": {\"claimName\": parameters['shared_pvc']}}],\n",
        "                    containers=[ContainerOverride(name=\"node\", volume_mounts=[{\"name\": \"shared\", \"mountPath\": \"/shared\"}])]\n",
        "                )\n",
        "            )\n",
        "        ),\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Monitor Progress\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_client.wait_for_job_status(name=job, status={\"Running\"}, timeout=300)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_ = trainer_client.get_job_logs(name=job, follow=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_client.wait_for_job_status(name=job, status={\"Complete\", \"Failed\"}, timeout=3600)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MLflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mlflow\n",
        "\n",
        "mlflow.set_tracking_uri(parameters['mlflow_uri'])\n",
        "experiment = mlflow.get_experiment_by_name(parameters['mlflow_experiment'])\n",
        "runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id], max_results=5, order_by=[\"start_time DESC\"])\n",
        "runs[[\"tags.mlflow.runName\", \"metrics.best_mape\"]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleanup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# trainer_client.delete_job(name=job)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
