{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sales Forecasting - Distributed Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q kubeflow-training mlflow yamlmagic\n",
        "%load_ext yamlmagic\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%yaml parameters\n",
        "\n",
        "# =============================================================================\n",
        "# Cluster Configuration\n",
        "# =============================================================================\n",
        "namespace: feast-trainer-demo\n",
        "shared_pvc: feast-pvc\n",
        "runtime: torch-distributed\n",
        "\n",
        "# =============================================================================\n",
        "# Training Hyperparameters\n",
        "# =============================================================================\n",
        "epochs: 50\n",
        "batch_size: 256\n",
        "learning_rate: 0.001\n",
        "\n",
        "# =============================================================================\n",
        "# Model Architecture\n",
        "# =============================================================================\n",
        "model:\n",
        "  hidden_dims: [256, 128, 64]\n",
        "  dropout: 0.2\n",
        "\n",
        "# =============================================================================\n",
        "# Feature Columns\n",
        "# =============================================================================\n",
        "features:\n",
        "  - lag_1\n",
        "  - lag_2\n",
        "  - lag_4\n",
        "  - lag_8\n",
        "  - lag_52\n",
        "  - rolling_mean_4w\n",
        "  - store_size\n",
        "  - temperature\n",
        "  - fuel_price\n",
        "  - cpi\n",
        "  - unemployment\n",
        "\n",
        "# =============================================================================\n",
        "# Distributed Training\n",
        "# =============================================================================\n",
        "num_workers: 1\n",
        "resources_per_worker:\n",
        "  cpu: 4\n",
        "  memory: 16Gi\n",
        "  \n",
        "# GPU Configuration: \"none\", \"nvidia\", or \"amd\"\n",
        "gpu_type: nvidia\n",
        "gpu_count: 1\n",
        "\n",
        "# =============================================================================\n",
        "# MLflow Tracking\n",
        "# =============================================================================\n",
        "mlflow:\n",
        "  experiment_name: sales-forecasting\n",
        "\n",
        "# =============================================================================\n",
        "# Data Paths (must match PVC mount: /shared)\n",
        "# =============================================================================\n",
        "paths:\n",
        "  data_dir: /shared/data\n",
        "  model_dir: /shared/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract key parameters for convenience\n",
        "NAMESPACE = parameters['namespace']\n",
        "SHARED_PVC = parameters['shared_pvc']\n",
        "RUNTIME = parameters['runtime']\n",
        "MLFLOW_URI = f\"http://mlflow.{NAMESPACE}.svc.cluster.local:5000\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Authentication\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "K8S_TOKEN = os.getenv(\"K8S_TOKEN\", \"<YOUR_TOKEN>\")\n",
        "K8S_API_SERVER = os.getenv(\"K8S_API_SERVER\", \"<YOUR_API_SERVER>\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from kubernetes import client as k8s\n",
        "from kubeflow.training import TrainerClient, CustomTrainer\n",
        "from kubeflow.training.types import KubernetesBackendConfig\n",
        "from kubeflow.training.types import (\n",
        "    PodTemplateOverrides, PodTemplateOverride,\n",
        "    PodSpecOverride, ContainerOverride,\n",
        "    Labels, Annotations\n",
        ")\n",
        "\n",
        "cfg = k8s.Configuration()\n",
        "if K8S_TOKEN and K8S_API_SERVER:\n",
        "    cfg.host = K8S_API_SERVER\n",
        "    cfg.verify_ssl = False\n",
        "    cfg.api_key = {\"authorization\": f\"Bearer {K8S_TOKEN}\"}\n",
        "\n",
        "trainer_client = TrainerClient(\n",
        "    KubernetesBackendConfig(\n",
        "        namespace=NAMESPACE,\n",
        "        client_configuration=cfg if K8S_TOKEN else None\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Runtime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "runtime = trainer_client.get_runtime(RUNTIME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_sales_model(parameters):\n",
        "    \"\"\"\n",
        "    Distributed training with MLflow best practices:\n",
        "    - Tags, comprehensive params, per-epoch metrics\n",
        "    - MAPE, R², MAE, RMSE tracking\n",
        "    - Training plots and organized artifacts\n",
        "    \"\"\"\n",
        "    import os, json, time\n",
        "    import torch, torch.nn as nn, torch.distributed as dist\n",
        "    import pandas as pd, numpy as np\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "    from pathlib import Path\n",
        "    from datetime import datetime\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # =========================================================================\n",
        "    # Device Detection\n",
        "    # =========================================================================\n",
        "    if torch.cuda.is_available():\n",
        "        is_rocm = hasattr(torch.version, 'hip') and torch.version.hip is not None\n",
        "        device_type = \"rocm\" if is_rocm else \"cuda\"\n",
        "        backend = \"nccl\"\n",
        "        local_rank = int(os.getenv(\"LOCAL_RANK\", 0))\n",
        "        torch.cuda.set_device(local_rank)\n",
        "        device = torch.device(\"cuda\", local_rank)\n",
        "    else:\n",
        "        device, backend, device_type = torch.device(\"cpu\"), \"gloo\", \"cpu\"\n",
        "\n",
        "    # =========================================================================\n",
        "    # Distributed Setup\n",
        "    # =========================================================================\n",
        "    dist.init_process_group(backend=backend)\n",
        "    rank, world_size = dist.get_rank(), dist.get_world_size()\n",
        "    \n",
        "    gpu_name, gpu_mem_gb = \"\", 0\n",
        "    if rank == 0:\n",
        "        if device_type != \"cpu\":\n",
        "            gpu_name = torch.cuda.get_device_name(0)\n",
        "            gpu_mem_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "            print(f\"Device: {device_type.upper()} ({gpu_name}, {gpu_mem_gb:.1f}GB) | Workers: {world_size}\")\n",
        "        else:\n",
        "            print(f\"Device: CPU | Workers: {world_size}\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # Configuration\n",
        "    # =========================================================================\n",
        "    mlflow_uri = os.getenv(\"MLFLOW_TRACKING_URI\", \"http://mlflow:5000\")\n",
        "    data_dir = parameters.get('paths', {}).get('data_dir', '/shared/data')\n",
        "    model_dir = parameters.get('paths', {}).get('model_dir', '/shared/models')\n",
        "    epochs = parameters.get('epochs', 50)\n",
        "    batch_size = parameters.get('batch_size', 256)\n",
        "    lr = parameters.get('learning_rate', 0.001)\n",
        "    feature_cols = parameters.get('features', [])\n",
        "    hidden_dims = parameters.get('model', {}).get('hidden_dims', [256, 128, 64])\n",
        "    dropout = parameters.get('model', {}).get('dropout', 0.2)\n",
        "\n",
        "    # =========================================================================\n",
        "    # Model Definition\n",
        "    # =========================================================================\n",
        "    class SalesMLP(nn.Module):\n",
        "        def __init__(self, input_dim, hidden_dims, dropout):\n",
        "            super().__init__()\n",
        "            layers = []\n",
        "            prev = input_dim\n",
        "            for h in hidden_dims:\n",
        "                layers.extend([nn.Linear(prev, h), nn.BatchNorm1d(h), nn.ReLU(), nn.Dropout(dropout)])\n",
        "                prev = h\n",
        "            layers.append(nn.Linear(prev, 1))\n",
        "            self.net = nn.Sequential(*layers)\n",
        "        def forward(self, x): return self.net(x).squeeze(-1)\n",
        "\n",
        "    # =========================================================================\n",
        "    # Load Data\n",
        "    # =========================================================================\n",
        "    df = pd.read_parquet(f\"{data_dir}/features.parquet\")\n",
        "    cols = [c for c in feature_cols if c in df.columns]\n",
        "    df = df.dropna(subset=cols + [\"weekly_sales\"])\n",
        "    X, y = df[cols].values, df[\"weekly_sales\"].values\n",
        "    data_hash = f\"{len(df)}-{len(cols)}f\"\n",
        "    \n",
        "    if rank == 0:\n",
        "        print(f\"Data: {len(df):,} samples, {len(cols)} features\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # Preprocessing\n",
        "    # =========================================================================\n",
        "    scaler_X, scaler_y = StandardScaler(), StandardScaler()\n",
        "    X_scaled = scaler_X.fit_transform(X)\n",
        "    y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "    # =========================================================================\n",
        "    # Model + DDP\n",
        "    # =========================================================================\n",
        "    model = SalesMLP(len(cols), hidden_dims, dropout).to(device)\n",
        "    if world_size > 1:\n",
        "        model = nn.parallel.DistributedDataParallel(model, device_ids=[device.index] if device_type != \"cpu\" else None)\n",
        "    \n",
        "    train_dataset = torch.utils.data.TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
        "    sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
        "    X_test_t = torch.FloatTensor(X_test).to(device)\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "    best_val_loss, best_mape, best_epoch = float('inf'), float('inf'), 0\n",
        "    best_state = None\n",
        "    history = {\"train_loss\": [], \"val_loss\": [], \"mae\": [], \"rmse\": [], \"mape\": [], \"r2\": [], \"lr\": []}\n",
        "\n",
        "    # =========================================================================\n",
        "    # MLflow Setup (rank 0)\n",
        "    # =========================================================================\n",
        "    mlflow_active = False\n",
        "    if rank == 0:\n",
        "        try:\n",
        "            import mlflow\n",
        "            mlflow.set_tracking_uri(mlflow_uri)\n",
        "            exp_name = parameters.get('mlflow', {}).get('experiment_name', 'sales-forecasting')\n",
        "            run_name = os.getenv(\"RUN_NAME\", f\"train-{datetime.now().strftime('%m%d-%H%M%S')}\")\n",
        "            mlflow.set_experiment(exp_name)\n",
        "            mlflow.start_run(run_name=run_name, description=f\"Sales forecasting with {len(cols)} features\")\n",
        "            \n",
        "            # Tags\n",
        "            mlflow.set_tags({\"model_type\": \"SalesMLP\", \"framework\": \"pytorch\", \"task\": \"regression\",\n",
        "                \"device\": device_type, \"gpu_name\": gpu_name or \"N/A\", \"data_hash\": data_hash, \"environment\": \"kubeflow\"})\n",
        "            \n",
        "            # Parameters\n",
        "            mlflow.log_params({\"epochs\": epochs, \"batch_size\": batch_size, \"learning_rate\": lr,\n",
        "                \"optimizer\": \"AdamW\", \"weight_decay\": 1e-5, \"scheduler\": \"CosineAnnealingLR\",\n",
        "                \"hidden_dims\": str(hidden_dims), \"dropout\": dropout, \"num_features\": len(cols),\n",
        "                \"train_samples\": len(X_train), \"test_samples\": len(X_test), \"world_size\": world_size,\n",
        "                \"torch_version\": torch.__version__, \"gpu_memory_gb\": f\"{gpu_mem_gb:.1f}\" if gpu_mem_gb else \"N/A\"})\n",
        "            mlflow_active = True\n",
        "            print(f\"MLflow: tracking at {mlflow_uri}\")\n",
        "        except Exception as e:\n",
        "            print(f\"MLflow init: {e}\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # Training Loop\n",
        "    # =========================================================================\n",
        "    for epoch in range(epochs):\n",
        "        sampler.set_epoch(epoch)\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        \n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model(xb), yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_losses.append(loss.item())\n",
        "        \n",
        "        current_lr = scheduler.get_last_lr()[0]\n",
        "        scheduler.step()\n",
        "        \n",
        "        # Evaluation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            y_pred_scaled = model(X_test_t).cpu().numpy()\n",
        "            val_loss = criterion(torch.FloatTensor(y_pred_scaled), torch.FloatTensor(y_test)).item()\n",
        "            \n",
        "            y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
        "            y_true = scaler_y.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
        "            \n",
        "            mae = mean_absolute_error(y_true, y_pred)\n",
        "            rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "            r2 = r2_score(y_true, y_pred)\n",
        "            mask = np.abs(y_true) > 100  # Avoid division by near-zero\n",
        "            mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100 if mask.sum() > 0 else 0.0\n",
        "        \n",
        "        train_loss = np.mean(train_losses)\n",
        "        for k, v in [(\"train_loss\", train_loss), (\"val_loss\", val_loss), (\"mae\", mae), (\"rmse\", rmse), (\"mape\", mape), (\"r2\", r2), (\"lr\", current_lr)]:\n",
        "            history[k].append(v)\n",
        "        \n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss, best_mape, best_epoch = val_loss, mape, epoch\n",
        "            if rank == 0:\n",
        "                base_model = model.module if hasattr(model, 'module') else model\n",
        "                best_state = base_model.state_dict().copy()\n",
        "        \n",
        "        if rank == 0:\n",
        "            if mlflow_active:\n",
        "                try: mlflow.log_metrics({\"train_loss\": train_loss, \"val_loss\": val_loss, \"mae\": mae, \"rmse\": rmse, \"mape\": mape, \"r2\": r2, \"learning_rate\": current_lr}, step=epoch)\n",
        "                except: pass\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                print(f\"Epoch {epoch+1}/{epochs} | Val: {val_loss:.6f} | MAPE: {mape:.2f}% | R²: {r2:.4f}\")\n",
        "\n",
        "    # =========================================================================\n",
        "    # Save Model & Artifacts (rank 0)\n",
        "    # =========================================================================\n",
        "    dist.barrier()\n",
        "    training_duration = time.time() - start_time\n",
        "    \n",
        "    if rank == 0:\n",
        "        import joblib\n",
        "        Path(model_dir).mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        torch.save(best_state, f\"{model_dir}/best_model.pt\")\n",
        "        joblib.dump({\"scaler_X\": scaler_X, \"scaler_y\": scaler_y, \"feature_cols\": cols}, f\"{model_dir}/scalers.joblib\")\n",
        "        \n",
        "        metadata = {\"model_type\": \"SalesMLP\", \"input_dim\": len(cols), \"hidden_dims\": hidden_dims, \"dropout\": dropout,\n",
        "            \"feature_columns\": cols, \"best_val_loss\": float(best_val_loss), \"best_mape\": float(best_mape),\n",
        "            \"best_epoch\": best_epoch, \"total_epochs\": epochs, \"device_type\": device_type,\n",
        "            \"training_duration_sec\": training_duration, \"data_hash\": data_hash, \"created_at\": datetime.now().isoformat()}\n",
        "        with open(f\"{model_dir}/model_metadata.json\", \"w\") as f: json.dump(metadata, f, indent=2)\n",
        "        with open(f\"{model_dir}/training_history.json\", \"w\") as f: json.dump(history, f)\n",
        "        \n",
        "        # Training plots\n",
        "        try:\n",
        "            import matplotlib\n",
        "            matplotlib.use('Agg')\n",
        "            import matplotlib.pyplot as plt\n",
        "            fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "            axes[0, 0].plot(history[\"train_loss\"], label=\"Train\"); axes[0, 0].plot(history[\"val_loss\"], label=\"Val\")\n",
        "            axes[0, 0].axvline(best_epoch, color='r', linestyle='--', alpha=0.5); axes[0, 0].set_title(\"Loss\"); axes[0, 0].legend(); axes[0, 0].grid(True, alpha=0.3)\n",
        "            axes[0, 1].plot(history[\"mape\"], color=\"green\"); axes[0, 1].axhline(best_mape, color='r', linestyle='--', alpha=0.5)\n",
        "            axes[0, 1].set_title(f\"MAPE (Best: {best_mape:.2f}%)\"); axes[0, 1].grid(True, alpha=0.3)\n",
        "            axes[1, 0].plot(history[\"r2\"], color=\"purple\"); axes[1, 0].set_title(\"R² Score\"); axes[1, 0].grid(True, alpha=0.3)\n",
        "            axes[1, 1].plot(history[\"lr\"], color=\"orange\"); axes[1, 1].set_title(\"Learning Rate\"); axes[1, 1].grid(True, alpha=0.3)\n",
        "            plt.tight_layout(); plt.savefig(f\"{model_dir}/training_curves.png\", dpi=150); plt.close()\n",
        "        except: pass\n",
        "        \n",
        "        # MLflow artifacts\n",
        "        if mlflow_active:\n",
        "            try:\n",
        "                mlflow.log_metrics({\"best_val_loss\": best_val_loss, \"best_mape\": best_mape, \"best_epoch\": best_epoch,\n",
        "                    \"final_r2\": history[\"r2\"][-1], \"training_duration_min\": training_duration / 60})\n",
        "                mlflow.log_artifact(f\"{model_dir}/best_model.pt\", \"model\")\n",
        "                mlflow.log_artifact(f\"{model_dir}/scalers.joblib\", \"preprocessing\")\n",
        "                mlflow.log_artifact(f\"{model_dir}/model_metadata.json\", \"metadata\")\n",
        "                mlflow.log_artifact(f\"{model_dir}/training_history.json\", \"metrics\")\n",
        "                if Path(f\"{model_dir}/training_curves.png\").exists(): mlflow.log_artifact(f\"{model_dir}/training_curves.png\", \"plots\")\n",
        "                mlflow.end_run()\n",
        "            except Exception as e:\n",
        "                print(f\"MLflow artifacts: {e}\")\n",
        "                try: mlflow.end_run()\n",
        "                except: pass\n",
        "        \n",
        "        print(f\"Done! Best MAPE: {best_mape:.2f}% @ epoch {best_epoch} | Duration: {training_duration/60:.1f}min\")\n",
        "    \n",
        "    dist.barrier()\n",
        "    dist.destroy_process_group()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Submit Training Job\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "job_id = datetime.now().strftime(\"%m%d-%H%M\")\n",
        "job_name = f\"sales-training-{job_id}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build resource spec based on GPU type\n",
        "resources = {\n",
        "    \"cpu\": parameters['resources_per_worker']['cpu'],\n",
        "    \"memory\": parameters['resources_per_worker']['memory'],\n",
        "}\n",
        "\n",
        "gpu_type = parameters.get('gpu_type', 'none')\n",
        "gpu_count = parameters.get('gpu_count', 0)\n",
        "\n",
        "if gpu_type == 'nvidia' and gpu_count > 0:\n",
        "    resources[\"nvidia.com/gpu\"] = gpu_count\n",
        "elif gpu_type == 'amd' and gpu_count > 0:\n",
        "    resources[\"amd.com/gpu\"] = gpu_count\n",
        "\n",
        "# Submit job\n",
        "job = trainer_client.train(\n",
        "    trainer=CustomTrainer(\n",
        "        func=train_sales_model,\n",
        "        num_nodes=parameters['num_workers'],\n",
        "        resources_per_node=resources,\n",
        "        packages_to_install=[\"scikit-learn\", \"pandas\", \"pyarrow\", \"joblib\", \"mlflow\", \"matplotlib\"],\n",
        "        env={\"MLFLOW_TRACKING_URI\": MLFLOW_URI, \"RUN_NAME\": f\"train-{job_id}\"},\n",
        "    ),\n",
        "    runtime=runtime,\n",
        "    parameters=parameters,\n",
        "    options=[\n",
        "        Labels({\"app\": \"sales-forecasting\", \"job-type\": \"training\", \"run-id\": job_id}),\n",
        "        Annotations({\"description\": f\"Sales forecasting - {job_id}\"}),\n",
        "        PodTemplateOverrides(\n",
        "            PodTemplateOverride(\n",
        "                target_jobs=[\"node\"],\n",
        "                spec=PodSpecOverride(\n",
        "                    volumes=[{\"name\": \"shared\", \"persistentVolumeClaim\": {\"claimName\": SHARED_PVC}}],\n",
        "                    containers=[ContainerOverride(name=\"node\", volume_mounts=[{\"name\": \"shared\", \"mountPath\": \"/shared\"}])]\n",
        "                )\n",
        "            )\n",
        "        ),\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Monitor Progress\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_client.wait_for_job_status(name=job, status={\"Running\"}, timeout=300)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_ = trainer_client.get_job_logs(name=job, follow=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer_client.wait_for_job_status(name=job, status={\"Complete\", \"Failed\"}, timeout=3600)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MLflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mlflow\n",
        "\n",
        "mlflow.set_tracking_uri(MLFLOW_URI)\n",
        "experiment = mlflow.get_experiment_by_name(parameters['mlflow']['experiment_name'])\n",
        "runs = mlflow.search_runs(\n",
        "    experiment_ids=[experiment.experiment_id],\n",
        "    max_results=5,\n",
        "    order_by=[\"start_time DESC\"]\n",
        ")\n",
        "cols = [\"tags.mlflow.runName\", \"metrics.best_mape\", \"metrics.final_r2\", \"metrics.best_epoch\", \"metrics.training_duration_min\", \"tags.device\"]\n",
        "display_cols = [c for c in cols if c in runs.columns]\n",
        "runs[display_cols]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleanup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# trainer_client.delete_job(name=job)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
