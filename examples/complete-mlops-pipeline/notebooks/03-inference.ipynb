{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03 - Model Serving & Inference\n",
        "\n",
        "![Workflow](../docs/03-inference-workflow.png)\n",
        "\n",
        "**KServe \u2192 Feast Feature Server \u2192 Predictions**\n",
        "\n",
        "**Prerequisites:**\n",
        "1. `01-feast-features.ipynb` completed\n",
        "2. `02-training.ipynb` completed\n",
        "3. KServe deployed: `kubectl apply -f ../manifests/08-kserve-inference.yaml`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q requests pandas tqdm\n",
        "import requests\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "NAMESPACE = \"feast-trainer-demo\"\n",
        "SERVICE = \"sales-forecast\"\n",
        "\n",
        "# In-cluster URL (from notebook pod)\n",
        "ENDPOINT = f\"http://{SERVICE}.{NAMESPACE}.svc.cluster.local:8080\"\n",
        "\n",
        "# Or use Route URL (from outside cluster)\n",
        "# ENDPOINT = \"https://sales-forecast-feast-trainer-demo.apps.your-cluster.com\"\n",
        "\n",
        "print(f\"Endpoint: {ENDPOINT}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Health Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    r = requests.get(f\"{ENDPOINT}/health\", timeout=10)\n",
        "    print(f\"\u2705 Health: {r.json()}\")\n",
        "except Exception as e:\n",
        "    print(f\"\u274c Service not reachable: {e}\")\n",
        "    print(\"\\nDeploy KServe first:\")\n",
        "    print(\"  kubectl apply -f ../manifests/08-kserve-inference.yaml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    r = requests.get(f\"{ENDPOINT}/v1/models/{SERVICE}\", timeout=10)\n",
        "    info = r.json()\n",
        "    print(f\"Model: {info.get('name')}\")\n",
        "    print(f\"MAPE: {info.get('best_mape')}%\")\n",
        "    print(f\"Features: {info.get('features', [])[:5]}...\")\n",
        "except Exception as e:\n",
        "    print(f\"Model info: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Real-time Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Single prediction with Feast features\n",
        "entity = {\"store_id\": 1, \"dept_id\": 3}\n",
        "\n",
        "t0 = time.time()\n",
        "r = requests.post(f\"{ENDPOINT}/v1/models/{SERVICE}:predict-with-feast\", json={\"entities\": [entity]}, timeout=30)\n",
        "latency = (time.time() - t0) * 1000\n",
        "\n",
        "if r.status_code == 200:\n",
        "    result = r.json()\n",
        "    print(f\"\u2705 Store {entity['store_id']}, Dept {entity['dept_id']}: ${result['predictions'][0]:,.0f}\")\n",
        "    print(f\"   Latency: {latency:.0f}ms\")\n",
        "else:\n",
        "    print(f\"\u274c Error: {r.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Batch Scoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Score multiple entities\n",
        "entities = [{\"store_id\": s, \"dept_id\": d} for s in [1, 10, 25, 45] for d in [1, 5, 10, 14]]\n",
        "print(f\"Scoring {len(entities)} entities...\")\n",
        "\n",
        "preds = []\n",
        "for e in tqdm(entities):\n",
        "    try:\n",
        "        r = requests.post(f\"{ENDPOINT}/v1/models/{SERVICE}:predict-with-feast\", json={\"entities\": [e]}, timeout=30)\n",
        "        if r.status_code == 200:\n",
        "            preds.append({**e, \"prediction\": r.json()['predictions'][0]})\n",
        "        else:\n",
        "            preds.append({**e, \"prediction\": None, \"error\": r.status_code})\n",
        "    except Exception as ex:\n",
        "        preds.append({**e, \"prediction\": None, \"error\": str(ex)})\n",
        "\n",
        "results = pd.DataFrame(preds)\n",
        "print(f\"\\n\u2705 {len(results)} predictions\")\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'prediction' in results.columns and results['prediction'].notna().any():\n",
        "    print(f\"\ud83d\udcca Summary:\")\n",
        "    print(f\"   Min: ${results['prediction'].min():,.0f}\")\n",
        "    print(f\"   Max: ${results['prediction'].max():,.0f}\")\n",
        "    print(f\"   Mean: ${results['prediction'].mean():,.0f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "os.makedirs('/shared/predictions', exist_ok=True)\n",
        "path = f\"/shared/predictions/batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}.parquet\"\n",
        "results.to_parquet(path, index=False)\n",
        "print(f\"\u2705 Saved: {path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "| Component | Status |\n",
        "|-----------|--------|\n",
        "| KServe InferenceService | Model serving |\n",
        "| Feast Feature Server | Online feature retrieval |\n",
        "| `/predict-with-feast` | Entity \u2192 Features \u2192 Prediction |\n",
        "\n",
        "**Key:** Same `inference_features` Feature Service ensures train-serve consistency."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}