{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01 - Feast Feature Store Setup\n",
        "\n",
        "![Workflow](../docs/01-features-workflow.png)\n",
        "\n",
        "**Raw Data \u2192 Feature Engineering \u2192 Feast Apply \u2192 Materialize**\n",
        "\n",
        "**Prerequisites:** PostgreSQL, PVC, RayCluster running (see `manifests/00-04`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q \"feast[postgres]==0.59.0\" pandas pyarrow psycopg2-binary\n",
        "import os, shutil, subprocess\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timedelta, timezone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "FEATURE_REPO = Path(\"/shared/feature_repo\")\n",
        "DATA_DIR = Path(\"/shared/data\")\n",
        "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "START_DATE, WEEKS, STORES, DEPTS, SEED = \"2022-01-01\", 104, 45, 14, 42\n",
        "print(f\"Records: {WEEKS * STORES * DEPTS:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Sales Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.random.seed(SEED)\n",
        "base_date = datetime.fromisoformat(START_DATE).replace(tzinfo=timezone.utc)\n",
        "HOLIDAYS = {6, 27, 36, 47, 51}\n",
        "\n",
        "records = []\n",
        "for week in range(WEEKS):\n",
        "    dt = base_date + timedelta(weeks=week)\n",
        "    woy, month = dt.isocalendar()[1], dt.month\n",
        "    seasonal = 1 + 0.3 * np.sin(2 * np.pi * woy / 52)\n",
        "    for s in range(1, STORES + 1):\n",
        "        for d in range(1, DEPTS + 1):\n",
        "            sales = max(0, (50000 + s*5000) * (0.5 + d*0.2) * seasonal * (1.5 if woy in HOLIDAYS else 1) + np.random.normal(0, 2000))\n",
        "            records.append({\"store_id\": s, \"dept_id\": d, \"event_timestamp\": dt, \"weekly_sales\": round(sales, 2),\n",
        "                \"week_of_year\": woy, \"month\": month, \"quarter\": (month-1)//3+1, \"is_holiday\": int(woy in HOLIDAYS),\n",
        "                \"temperature\": round(60 + 20*np.sin(2*np.pi*woy/52) + np.random.normal(0,5), 1),\n",
        "                \"fuel_price\": round(3 + 0.5*np.random.random(), 2), \"cpi\": round(220 + week*0.1, 1), \"unemployment\": round(5 + np.random.normal(0, 0.5), 1)})\n",
        "\n",
        "sales_df = pd.DataFrame(records).sort_values([\"store_id\", \"dept_id\", \"event_timestamp\"]).reset_index(drop=True)\n",
        "print(f\"Generated {len(sales_df):,} rows\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lag + rolling features\n",
        "for lag in [1, 2, 4, 8]:\n",
        "    sales_df[f\"lag_{lag}\"] = sales_df.groupby([\"store_id\", \"dept_id\"])[\"weekly_sales\"].shift(lag)\n",
        "\n",
        "g = sales_df.groupby([\"store_id\", \"dept_id\"])[\"weekly_sales\"]\n",
        "sales_df[\"rolling_mean_4w\"] = g.transform(lambda x: x.rolling(4, min_periods=1).mean())\n",
        "sales_df[\"rolling_std_4w\"] = g.transform(lambda x: x.rolling(4, min_periods=2).std()).fillna(0)\n",
        "sales_df[\"sales_vs_avg\"] = (sales_df[\"weekly_sales\"] / sales_df[\"rolling_mean_4w\"].replace(0, 1)).fillna(1)\n",
        "\n",
        "for lag in [1, 2, 4, 8]:\n",
        "    sales_df[f\"lag_{lag}\"] = sales_df[f\"lag_{lag}\"].fillna(sales_df[\"rolling_mean_4w\"])\n",
        "sales_df = sales_df.fillna(0)\n",
        "print(f\"Features: {len(sales_df.columns)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save\n",
        "sales_df.to_parquet(DATA_DIR / \"sales_features.parquet\", index=False)\n",
        "stores = pd.DataFrame([{\"store_id\": s, \"dept_id\": d, \"event_timestamp\": base_date, \"store_type\": [\"A\",\"B\",\"C\"][s%3], \"store_size\": 100000+s*10000, \"region\": f\"region_{(s-1)//15+1}\"} for s in range(1, STORES+1) for d in range(1, DEPTS+1)])\n",
        "stores.to_parquet(DATA_DIR / \"store_features.parquet\", index=False)\n",
        "print(f\"\u2705 Saved to {DATA_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup Feast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "FEATURE_REPO.mkdir(parents=True, exist_ok=True)\n",
        "src_dir = Path(\"../feature_repo\")\n",
        "for f in [\"feature_store.yaml\", \"feature_store_ray.yaml\", \"features.py\"]:\n",
        "    src = src_dir / f\n",
        "    if src.exists():\n",
        "        shutil.copy(src, FEATURE_REPO / f)\n",
        "        print(f\"\u2705 {f}\")\n",
        "    else:\n",
        "        print(f\"\u274c Missing: {src}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feast Apply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir(str(FEATURE_REPO))\n",
        "result = subprocess.run([\"feast\", \"apply\"], capture_output=True, text=True)\n",
        "print(result.stdout)\n",
        "if result.returncode != 0:\n",
        "    print(f\"ERROR: {result.stderr}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feast Materialize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "end_ts = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
        "result = subprocess.run([\"feast\", \"materialize\", f\"{START_DATE}T00:00:00\", end_ts], capture_output=True, text=True, cwd=str(FEATURE_REPO))\n",
        "print(result.stdout)\n",
        "if result.returncode != 0:\n",
        "    print(f\"ERROR: {result.stderr}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Verify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feast import FeatureStore\n",
        "store = FeatureStore(repo_path=str(FEATURE_REPO))\n",
        "print(f\"Views: {[fv.name for fv in store.list_feature_views()]}\")\n",
        "print(f\"Services: {[fs.name for fs in store.list_feature_services()]}\")\n",
        "\n",
        "features = store.get_online_features(features=[\"sales_features:weekly_sales\", \"sales_features:lag_1\"], entity_rows=[{\"store_id\": 1, \"dept_id\": 1}]).to_dict()\n",
        "print(f\"\\n\u2705 Online: {features}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Next:** `02-training.ipynb`"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}