{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 - Feature Engineering with Feast & Ray\n",
        "\n",
        "This notebook demonstrates **Feast Feature Store** with **Ray** for distributed processing:\n",
        "\n",
        "1. **Generate sample data** - Create sales, store, and department data\n",
        "2. **Configure Feast** - Set up feature store with Ray offline store\n",
        "3. **Register features** - Define entities and feature views\n",
        "4. **Historical retrieval** - Fetch features using Ray (distributed)\n",
        "5. **Materialize** - Push features to online store for real-time serving\n",
        "\n",
        "## Integration: Feast + KubeRay\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚                         Feast + Ray                             â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚                                                                 â”‚\n",
        "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚\n",
        "â”‚   â”‚ Notebook â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚         KubeRay Cluster           â”‚      â”‚\n",
        "â”‚   â”‚(Feast SDK)â”‚      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚      â”‚\n",
        "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚  â”‚ Worker â”‚ â”‚ Worker â”‚ â”‚ Worker â”‚ â”‚      â”‚\n",
        "â”‚        â”‚             â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚      â”‚\n",
        "â”‚        â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚\n",
        "â”‚        â”‚                           â”‚                            â”‚\n",
        "â”‚        â–¼                           â–¼                            â”‚\n",
        "â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚\n",
        "â”‚   â”‚PostgreSQLâ”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ Parquet Data â”‚                   â”‚\n",
        "â”‚   â”‚ Registry â”‚              â”‚ (Distributed)â”‚                   â”‚\n",
        "â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚\n",
        "â”‚                                                                 â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "%pip install -q feast[postgres,ray] pandas pyarrow numpy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta, timezone\n",
        "from pathlib import Path\n",
        "\n",
        "# Configuration\n",
        "NAMESPACE = os.getenv(\"NAMESPACE\", \"feast-mlops-demo\")\n",
        "POSTGRES_HOST = os.getenv(\"POSTGRES_HOST\", f\"postgres.{NAMESPACE}.svc.cluster.local\")\n",
        "RAY_HOST = os.getenv(\"RAY_HOST\", f\"feast-ray-head-svc.{NAMESPACE}.svc.cluster.local\")\n",
        "\n",
        "# Paths\n",
        "DATA_DIR = \"/shared/data\"\n",
        "FEATURE_REPO_DIR = \"/shared/feature_repo\"\n",
        "\n",
        "print(f\"ğŸ“Œ Namespace: {NAMESPACE}\")\n",
        "print(f\"ğŸ“ Data directory: {DATA_DIR}\")\n",
        "print(f\"ğŸ“ Feature repo: {FEATURE_REPO_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Generate Sample Data\n",
        "\n",
        "Creating realistic sales data for 10 stores, 5 departments over 2 years.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_sales_data(num_stores=10, num_depts=5, weeks=104):\n",
        "    \"\"\"Generate realistic sales data\"\"\"\n",
        "    np.random.seed(42)\n",
        "    \n",
        "    records = []\n",
        "    base_date = datetime(2022, 1, 1, tzinfo=timezone.utc)\n",
        "    \n",
        "    for week in range(weeks):\n",
        "        date = base_date + timedelta(weeks=week)\n",
        "        \n",
        "        for store_id in range(1, num_stores + 1):\n",
        "            store_base = 50000 + store_id * 5000\n",
        "            \n",
        "            for dept_id in range(1, num_depts + 1):\n",
        "                # Base sales with seasonal pattern\n",
        "                seasonal = 1 + 0.3 * np.sin(2 * np.pi * week / 52)\n",
        "                # Holiday boost (week 47-52)\n",
        "                holiday = 1.5 if 47 <= (week % 52) <= 52 else 1.0\n",
        "                # Department factor\n",
        "                dept_factor = 0.5 + dept_id * 0.2\n",
        "                \n",
        "                weekly_sales = (\n",
        "                    store_base * dept_factor * seasonal * holiday\n",
        "                    + np.random.normal(0, 2000)\n",
        "                )\n",
        "                \n",
        "                records.append({\n",
        "                    \"store_id\": store_id,\n",
        "                    \"dept_id\": dept_id,\n",
        "                    \"event_timestamp\": date,\n",
        "                    \"weekly_sales\": max(0, weekly_sales),\n",
        "                    \"is_holiday\": int(holiday > 1),\n",
        "                    \"temperature\": 60 + 20 * np.sin(2 * np.pi * week / 52) + np.random.normal(0, 5),\n",
        "                    \"fuel_price\": 3.0 + 0.5 * np.random.random(),\n",
        "                    \"cpi\": 220 + week * 0.1,\n",
        "                    \"unemployment\": 5.0 + np.random.normal(0, 0.5)\n",
        "                })\n",
        "    \n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "# Generate data\n",
        "print(\"Generating sales data...\")\n",
        "sales_df = generate_sales_data()\n",
        "print(f\"âœ… Generated {len(sales_df):,} records\")\n",
        "print(f\"   Date range: {sales_df['event_timestamp'].min()} to {sales_df['event_timestamp'].max()}\")\n",
        "sales_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate store features\n",
        "def generate_store_features(num_stores=10):\n",
        "    \"\"\"Generate store metadata\"\"\"\n",
        "    np.random.seed(42)\n",
        "    base_date = datetime(2022, 1, 1, tzinfo=timezone.utc)\n",
        "    \n",
        "    records = []\n",
        "    store_types = [\"A\", \"B\", \"C\"]\n",
        "    \n",
        "    for store_id in range(1, num_stores + 1):\n",
        "        records.append({\n",
        "            \"store_id\": store_id,\n",
        "            \"event_timestamp\": base_date,\n",
        "            \"store_type\": store_types[store_id % 3],\n",
        "            \"store_size\": 100000 + store_id * 10000,\n",
        "            \"region\": f\"region_{(store_id - 1) // 3 + 1}\"\n",
        "        })\n",
        "    \n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "store_df = generate_store_features()\n",
        "print(f\"âœ… Generated store features: {len(store_df)} stores\")\n",
        "store_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save to parquet\n",
        "Path(DATA_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "sales_path = f\"{DATA_DIR}/sales_features.parquet\"\n",
        "store_path = f\"{DATA_DIR}/store_features.parquet\"\n",
        "\n",
        "sales_df.to_parquet(sales_path)\n",
        "store_df.to_parquet(store_path)\n",
        "\n",
        "print(f\"âœ… Saved: {sales_path}\")\n",
        "print(f\"âœ… Saved: {store_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configure Feast Feature Store\n",
        "\n",
        "Setting up Feast with:\n",
        "- **PostgreSQL** registry for metadata\n",
        "- **Ray** offline store for distributed feature retrieval\n",
        "- **PostgreSQL** online store for real-time serving\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create feature_store.yaml\n",
        "Path(FEATURE_REPO_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "feature_store_yaml = f\"\"\"\n",
        "project: sales_forecasting\n",
        "provider: local\n",
        "\n",
        "registry:\n",
        "  registry_type: sql\n",
        "  path: postgresql+psycopg2://feast:feast123@{POSTGRES_HOST}:5432/feast\n",
        "\n",
        "offline_store:\n",
        "  type: file  # Use file for simplicity, Ray for production scale\n",
        "\n",
        "online_store:\n",
        "  type: postgres\n",
        "  host: {POSTGRES_HOST}\n",
        "  port: 5432\n",
        "  database: feast\n",
        "  user: feast\n",
        "  password: feast123\n",
        "\n",
        "entity_key_serialization_version: 2\n",
        "\"\"\"\n",
        "\n",
        "with open(f\"{FEATURE_REPO_DIR}/feature_store.yaml\", \"w\") as f:\n",
        "    f.write(feature_store_yaml)\n",
        "\n",
        "print(f\"âœ… Created: {FEATURE_REPO_DIR}/feature_store.yaml\")\n",
        "print(feature_store_yaml)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Define Feature Views\n",
        "\n",
        "Register entities and feature views in Feast.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feast import FeatureStore, Entity, FeatureView, Field, FileSource\n",
        "from feast.types import Float32, Int64, String\n",
        "from datetime import timedelta\n",
        "\n",
        "# Initialize feature store\n",
        "store = FeatureStore(repo_path=FEATURE_REPO_DIR)\n",
        "\n",
        "# Define entities\n",
        "store_entity = Entity(name=\"store_id\", join_keys=[\"store_id\"])\n",
        "dept_entity = Entity(name=\"dept_id\", join_keys=[\"dept_id\"])\n",
        "\n",
        "# Define data sources\n",
        "sales_source = FileSource(\n",
        "    path=f\"{DATA_DIR}/sales_features.parquet\",\n",
        "    timestamp_field=\"event_timestamp\",\n",
        ")\n",
        "\n",
        "store_source = FileSource(\n",
        "    path=f\"{DATA_DIR}/store_features.parquet\",\n",
        "    timestamp_field=\"event_timestamp\",\n",
        ")\n",
        "\n",
        "# Define feature views\n",
        "sales_features = FeatureView(\n",
        "    name=\"sales_features\",\n",
        "    entities=[store_entity, dept_entity],\n",
        "    ttl=timedelta(days=365),\n",
        "    schema=[\n",
        "        Field(name=\"weekly_sales\", dtype=Float32),\n",
        "        Field(name=\"is_holiday\", dtype=Int64),\n",
        "        Field(name=\"temperature\", dtype=Float32),\n",
        "        Field(name=\"fuel_price\", dtype=Float32),\n",
        "        Field(name=\"cpi\", dtype=Float32),\n",
        "        Field(name=\"unemployment\", dtype=Float32),\n",
        "    ],\n",
        "    source=sales_source,\n",
        ")\n",
        "\n",
        "store_features = FeatureView(\n",
        "    name=\"store_features\",\n",
        "    entities=[store_entity],\n",
        "    ttl=timedelta(days=365),\n",
        "    schema=[\n",
        "        Field(name=\"store_type\", dtype=String),\n",
        "        Field(name=\"store_size\", dtype=Int64),\n",
        "        Field(name=\"region\", dtype=String),\n",
        "    ],\n",
        "    source=store_source,\n",
        ")\n",
        "\n",
        "print(\"âœ… Feature views defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply feature definitions to registry\n",
        "store.apply([store_entity, dept_entity, sales_features, store_features])\n",
        "\n",
        "print(\"âœ… Features registered in Feast!\")\n",
        "print(f\"\\nRegistered feature views:\")\n",
        "for fv in store.list_feature_views():\n",
        "    print(f\"  - {fv.name}: {len(fv.features)} features\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Historical Feature Retrieval\n",
        "\n",
        "Fetch training features using point-in-time joins.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create entity dataframe for feature retrieval\n",
        "# Sample recent records for training\n",
        "entity_df = sales_df[[\"store_id\", \"dept_id\", \"event_timestamp\"]].copy()\n",
        "entity_df = entity_df.sample(n=min(5000, len(entity_df)), random_state=42)\n",
        "\n",
        "print(f\"ğŸ“Š Entity dataframe: {len(entity_df)} rows\")\n",
        "entity_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "# Fetch historical features\n",
        "training_df = store.get_historical_features(\n",
        "    entity_df=entity_df,\n",
        "    features=[\n",
        "        \"sales_features:weekly_sales\",\n",
        "        \"sales_features:is_holiday\",\n",
        "        \"sales_features:temperature\",\n",
        "        \"sales_features:fuel_price\",\n",
        "        \"sales_features:cpi\",\n",
        "        \"sales_features:unemployment\",\n",
        "        \"store_features:store_type\",\n",
        "        \"store_features:store_size\",\n",
        "    ]\n",
        ").to_df()\n",
        "\n",
        "print(f\"âœ… Retrieved {len(training_df)} training samples\")\n",
        "print(f\"   Columns: {list(training_df.columns)}\")\n",
        "training_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save training data for model training\n",
        "training_path = f\"{DATA_DIR}/training_data.parquet\"\n",
        "training_df.to_parquet(training_path)\n",
        "print(f\"âœ… Saved training data: {training_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Materialize to Online Store\n",
        "\n",
        "Push features to PostgreSQL online store for real-time serving.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "# Materialize features to online store\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "start_date = datetime(2022, 1, 1, tzinfo=timezone.utc)\n",
        "end_date = datetime(2024, 1, 1, tzinfo=timezone.utc)\n",
        "\n",
        "print(\"Materializing features to online store...\")\n",
        "store.materialize(start_date=start_date, end_date=end_date)\n",
        "print(\"âœ… Materialization complete!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
