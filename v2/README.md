# Sales Demand Forecasting - Industry-Grade Quickstart

An end-to-end ML pipeline demonstrating **Kubeflow Trainer + Feast Feature Store** integration on OpenShift AI / Red Hat AI.

## ğŸ¯ Key Results

| Metric | Value |
|--------|-------|
| **Model MAPE** | 9.9% |
| **Improvement** | 87.5% vs naive baseline |
| **Training Time** | ~30 seconds (4 GPUs) |
| **Feature Retrieval** | PostgreSQL online store |

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     OpenShift AI Cluster                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚ Data Prep Job   â”‚    â”‚ Feast PostgreSQLâ”‚                     â”‚
â”‚  â”‚ (Synthetic Data)â”‚â”€â”€â”€â–¶â”‚    (Registry,   â”‚                     â”‚
â”‚  â”‚ Feature Eng.    â”‚    â”‚  Online Store)  â”‚                     â”‚
â”‚  â”‚ feast apply     â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚                              â”‚
â”‚           â”‚                      â”‚                              â”‚
â”‚           â–¼                      â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚              Shared PVC (NFS)                   â”‚            â”‚
â”‚  â”‚  /shared/data     - Feature parquet files      â”‚            â”‚
â”‚  â”‚  /shared/models   - Trained models, scalers    â”‚            â”‚
â”‚  â”‚  /shared/feature_repo - Feast config           â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”˜            â”‚
â”‚                                                  â”‚              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚    TrainJob v2       â”‚     â”‚    Inference Job        â”‚       â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚       â”‚
â”‚  â”‚  â”‚ Feast SDK     â”‚   â”‚     â”‚  â”‚ Feast SDK     â”‚      â”‚       â”‚
â”‚  â”‚  â”‚ get_historicalâ”‚   â”‚     â”‚  â”‚ get_online    â”‚      â”‚       â”‚
â”‚  â”‚  â”‚ _features()   â”‚   â”‚     â”‚  â”‚ _features()   â”‚      â”‚       â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚       â”‚
â”‚  â”‚          â”‚           â”‚     â”‚          â”‚              â”‚       â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”   â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”      â”‚       â”‚
â”‚  â”‚  â”‚ PyTorch DDP   â”‚   â”‚     â”‚  â”‚ Model Predict â”‚      â”‚       â”‚
â”‚  â”‚  â”‚ (4 GPUs)      â”‚   â”‚     â”‚  â”‚ Compare Base  â”‚      â”‚       â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Components

| Component | Technology | Purpose |
|-----------|------------|---------|
| **Feature Store** | Feast + PostgreSQL | Feature registry, online serving |
| **Training** | Kubeflow Trainer v2 | Distributed PyTorch training |
| **Model** | MLP (256â†’128â†’64â†’1) | Sales forecasting |
| **Storage** | NFS PVC (RWX) | Shared data/models |
| **Runtime** | torch-with-storage | Custom ClusterTrainingRuntime |

## ğŸš€ Quick Start

### Prerequisites

- OpenShift AI / RHOAI cluster
- `kubectl` configured
- Namespace: `feast-trainer-demo`

### Deploy

```bash
# 1. Create namespace and storage
kubectl create namespace feast-trainer-demo
kubectl apply -f v2/manifests/02-pvc-shared-storage.yaml
kubectl apply -f v2/manifests/03-clustertrainingruntime.yaml

# 2. Deploy Feast PostgreSQL
kubectl apply -f v2/manifests/05-feast-postgres.yaml
kubectl wait --for=condition=available deployment/feast-postgres -n feast-trainer-demo --timeout=120s

# 3. Prepare data & register features
kubectl apply -f v2/manifests/data-prep-job.yaml
kubectl wait --for=condition=complete job/feast-data-prep -n feast-trainer-demo --timeout=300s

# 4. Train model (fetches features via Feast)
kubectl apply -f v2/manifests/04-trainjob.yaml
kubectl wait --for=jsonpath='{.status.state}'=Complete trainjob/sales-forecasting -n feast-trainer-demo --timeout=600s

# 5. Run inference
kubectl apply -f v2/manifests/07-inference-job.yaml
kubectl logs -n feast-trainer-demo -l job-name=feast-inference -f
```

## ğŸ“Š Features Used

### Sales Features (Historical)
- `lag_1`, `lag_2`, `lag_4`, `lag_8`, `lag_52` - Past sales
- `rolling_mean_4w`, `rolling_std_4w` - 4-week rolling stats
- `rolling_mean_8w`, `rolling_std_8w` - 8-week rolling stats
- `rolling_mean_52w` - 52-week (YoY) rolling mean

### Store Features (External)
- `store_size`, `temperature`, `fuel_price`, `cpi`, `unemployment`
- `markdown1` - `markdown5` - Promotion markdowns
- `is_holiday`, `week_of_year`, `month` - Calendar features

### No Data Leakage âœ…
- All lag features use `.shift(1)` before rolling
- Target (`weekly_sales`) never used as input feature
- Temporal train/val split (2010-2011 train, 2012 val)

## ğŸ”§ Configuration

### Feast Feature Store
```yaml
# feature_store.yaml
project: sales_forecasting
registry:
  registry_type: sql
  path: postgresql+psycopg://feast:feast123@feast-postgres:5432/feast
offline_store:
  type: file  # Parquet files
online_store:
  type: postgres  # Real-time serving
```

### Training Parameters
```yaml
# 04-trainjob.yaml
numNodes: 1
numProcPerNode: 4  # 4 GPUs
epochs: 10
batch_size: 256
learning_rate: 1e-3
```

## ğŸ“ File Structure

```
v2/
â”œâ”€â”€ manifests/
â”‚   â”œâ”€â”€ 01-namespace.yaml           # feast-trainer-demo
â”‚   â”œâ”€â”€ 02-pvc-shared-storage.yaml  # NFS PVCs
â”‚   â”œâ”€â”€ 03-clustertrainingruntime.yaml  # torch-with-storage
â”‚   â”œâ”€â”€ 04-trainjob.yaml            # Training with Feast
â”‚   â”œâ”€â”€ 05-feast-postgres.yaml      # PostgreSQL + init
â”‚   â”œâ”€â”€ 07-inference-job.yaml       # Inference with Feast
â”‚   â””â”€â”€ data-prep-job.yaml          # Data + feast apply
â”œâ”€â”€ feature_repo/
â”‚   â”œâ”€â”€ feature_store.yaml          # Feast config
â”‚   â””â”€â”€ features.py                 # Feature definitions
â””â”€â”€ README.md
```

## ğŸ“ Key Learnings

1. **Feast Integration**: Use `get_historical_features()` for training (point-in-time join), `get_online_features()` for real-time inference
2. **TrainJob v2**: Use `ClusterTrainingRuntime` for shared storage, not inline volume mounts
3. **OpenShift**: Use `nfs-csi` storage class for RWX access
4. **DDP Training**: `torchrun` with `PET_*` environment variables from TrainJob status

## ğŸ“ˆ Results

```
Model                            MAPE           RMSE            MAE
-------------------------------------------------------------------
Base (Random)                   62.0%         31,627         24,985
Naive (Mean)                    78.6%         28,376         23,847
Trained (Feast)                  9.9%          6,471          4,608

âœ… Improvement vs Naive: 87.5%
```

## ğŸ”— References

- [Kubeflow Trainer](https://github.com/opendatahub-io/trainer)
- [Kubeflow SDK](https://github.com/opendatahub-io/kubeflow-sdk)
- [Feast Feature Store](https://github.com/feast-dev/feast)
- [Red Hat AI Quickstarts](https://github.com/rh-ai-quickstarts)
