# Inference Job - Compare base vs trained model
apiVersion: batch/v1
kind: Job
metadata:
  name: model-inference
  namespace: feast-trainer-demo
spec:
  template:
    spec:
      restartPolicy: OnFailure
      containers:
      - name: inference
        image: registry.redhat.io/rhoai/odh-training-cuda128-torch28-py312-rhel9@sha256:bdc8cb781f005c11534a959fd57b8ba5133522e3bb4756d409e3111eeaf2e8ee
        env:
        - name: DATA_PATH
          value: /shared/data
        - name: MODEL_DIR
          value: /shared/models
        volumeMounts:
        - name: shared-storage
          mountPath: /shared
        command:
        - bash
        - -c
        - |
          pip install --quiet joblib scikit-learn
          
          cat > /tmp/inference.py << 'INFERENCE_SCRIPT'
          import os
          import numpy as np
          import pandas as pd
          import torch
          import torch.nn as nn
          import joblib
          
          DATA_PATH = os.environ.get("DATA_PATH", "/shared/data")
          MODEL_DIR = os.environ.get("MODEL_DIR", "/shared/models")
          VAL_START_DATE = "2012-01-01"
          
          print("=" * 60)
          print("MODEL INFERENCE & COMPARISON")
          print("=" * 60)
          
          # Model architecture
          class SalesMLP(nn.Module):
              def __init__(self, input_dim):
                  super().__init__()
                  self.net = nn.Sequential(
                      nn.Linear(input_dim, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(0.2),
                      nn.Linear(256, 128), nn.BatchNorm1d(128), nn.ReLU(), nn.Dropout(0.2),
                      nn.Linear(128, 64), nn.BatchNorm1d(64), nn.ReLU(), nn.Dropout(0.2),
                      nn.Linear(64, 1)
                  )
              def forward(self, x):
                  return self.net(x).squeeze(-1)
          
          # Load data
          print("\nLoading validation data...")
          df = pd.read_parquet(f"{DATA_PATH}/features.parquet")
          df["date"] = pd.to_datetime(df["date"])
          val_df = df[df["date"] >= VAL_START_DATE].copy()
          print(f"  Validation samples: {len(val_df):,}")
          
          # Load scalers
          scaler = joblib.load(f"{MODEL_DIR}/scaler.pkl")
          y_scaler = joblib.load(f"{MODEL_DIR}/y_scaler.pkl")
          feature_cols = joblib.load(f"{MODEL_DIR}/feature_cols.pkl")
          print(f"  Features: {len(feature_cols)}")
          
          # Prepare data
          X_val = val_df[feature_cols].fillna(0).values
          y_val = val_df["weekly_sales"].values
          X_val_scaled = scaler.transform(X_val)
          
          input_dim = X_val_scaled.shape[1]
          device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
          print(f"  Device: {device}")
          
          # Base model (random weights)
          print("\nCreating base model (random weights)...")
          torch.manual_seed(42)
          base_model = SalesMLP(input_dim).to(device)
          base_model.eval()
          
          # Trained model
          print("Loading trained model...")
          trained_model = SalesMLP(input_dim).to(device)
          trained_model.load_state_dict(torch.load(f"{MODEL_DIR}/best_model.pt", map_location=device))
          trained_model.eval()
          
          # Inference
          print("\nRunning inference...")
          X_tensor = torch.tensor(X_val_scaled, dtype=torch.float32).to(device)
          
          with torch.no_grad():
              base_preds_scaled = base_model(X_tensor).cpu().numpy()
              trained_preds_scaled = trained_model(X_tensor).cpu().numpy()
          
          # Unscale
          base_preds = y_scaler.inverse_transform(base_preds_scaled.reshape(-1, 1)).flatten()
          trained_preds = y_scaler.inverse_transform(trained_preds_scaled.reshape(-1, 1)).flatten()
          naive_preds = np.full_like(y_val, y_val.mean())
          
          # Metrics
          def calc_metrics(actual, predicted):
              mask = np.abs(actual) > 100
              if mask.sum() == 0:
                  return np.nan, np.nan, np.nan
              errors = actual[mask] - predicted[mask]
              mape = np.mean(np.abs(errors / actual[mask])) * 100
              rmse = np.sqrt(np.mean(errors ** 2))
              mae = np.mean(np.abs(errors))
              return mape, rmse, mae
          
          base_mape, base_rmse, base_mae = calc_metrics(y_val, base_preds)
          naive_mape, naive_rmse, naive_mae = calc_metrics(y_val, naive_preds)
          trained_mape, trained_rmse, trained_mae = calc_metrics(y_val, trained_preds)
          
          # Results
          print("\n" + "=" * 60)
          print("RESULTS COMPARISON")
          print("=" * 60)
          print(f"\n{'Model':<20} {'MAPE':>10} {'RMSE':>12} {'MAE':>12}")
          print("-" * 56)
          print(f"{'Base (Random)':<20} {base_mape:>9.1f}% {base_rmse:>11,.0f} {base_mae:>11,.0f}")
          print(f"{'Naive (Mean)':<20} {naive_mape:>9.1f}% {naive_rmse:>11,.0f} {naive_mae:>11,.0f}")
          print(f"{'Trained':<20} {trained_mape:>9.1f}% {trained_rmse:>11,.0f} {trained_mae:>11,.0f}")
          
          print("\n" + "=" * 60)
          print("IMPROVEMENT ANALYSIS")
          print("=" * 60)
          print(f"\nBase Model MAPE:    {base_mape:.1f}%")
          print(f"Naive Baseline:     {naive_mape:.1f}%")
          print(f"Trained Model MAPE: {trained_mape:.1f}%")
          
          imp_base = ((base_mape - trained_mape) / base_mape) * 100
          imp_naive = ((naive_mape - trained_mape) / naive_mape) * 100
          print(f"\nImprovement vs Base:  {imp_base:+.1f}%")
          print(f"Improvement vs Naive: {imp_naive:+.1f}%")
          
          # Samples
          print("\n" + "=" * 60)
          print("SAMPLE PREDICTIONS (first 10)")
          print("=" * 60)
          print(f"\n{'Actual':>12} {'Base':>12} {'Trained':>12} {'Error%':>10}")
          print("-" * 48)
          for i in range(min(10, len(y_val))):
              a, b, t = y_val[i], base_preds[i], trained_preds[i]
              e = abs(a - t) / a * 100 if a != 0 else 0
              print(f"{a:>12,.0f} {b:>12,.0f} {t:>12,.0f} {e:>9.1f}%")
          
          print("\n" + "=" * 60)
          print("INFERENCE COMPLETE")
          print("=" * 60)
          print(f"\nTrained model: {trained_mape:.1f}% MAPE")
          print(f"Samples: {len(y_val):,} | Mean sales: ${y_val.mean():,.0f}")
          INFERENCE_SCRIPT
          
          python /tmp/inference.py
      volumes:
      - name: shared-storage
        persistentVolumeClaim:
          claimName: shared-storage
