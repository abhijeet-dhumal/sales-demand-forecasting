# Feast Feature Store Configuration
# Using native Ray offline store + KubeRay mode (CodeFlare SDK handles TLS)
# Ref: https://docs.feast.dev/reference/offline-stores/ray

project: sales_forecasting
provider: local

# PostgreSQL registry for feature definitions
registry:
  registry_type: sql
  path: postgresql+psycopg://feast:feast123@feast-postgres.feast-trainer-demo.svc.cluster.local:5432/feast
  cache_ttl_seconds: 60

# Ray offline store with KubeRay integration
offline_store:
  type: ray
  storage_path: /shared/data/ray_storage
  use_kuberay: true
  kuberay_conf:
    cluster_name: "feast-ray"
    namespace: "feast-trainer-demo"
    # Auth handled via environment variables or service account
    skip_tls: true  # ODH uses internal TLS, CodeFlare handles it
  # Performance tuning
  broadcast_join_threshold_mb: 100
  max_parallelism_multiplier: 2
  target_partition_size_mb: 64
  enable_ray_logging: true

# Ray compute engine for distributed feature processing
batch_engine:
  type: ray.engine
  max_workers: 4
  enable_optimization: true
  broadcast_join_threshold_mb: 100
  target_partition_size_mb: 64
  enable_distributed_joins: true

# PostgreSQL online store for low-latency serving
online_store:
  type: postgres
  host: feast-postgres.feast-trainer-demo.svc.cluster.local
  port: 5432
  database: feast
  user: feast
  password: feast123

entity_key_serialization_version: 3
